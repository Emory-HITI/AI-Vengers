{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, matthews_corrcoef, auc, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate, add, GlobalAveragePooling2D, BatchNormalization, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from classification_models.tfkeras import Classifiers\n",
    "from tensorflow.keras.models import load_model\n",
    "import random as python_random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(2021)\n",
    "python_random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.read_csv('cspin_split_80-10-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('cspin_split_80-10-10_ver_C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = compare_df[compare_df.ViewPosition.isin(['LATERAL','LATERAL FLEX','LATERAL EXT'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13287"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = data_df.Image.str.split(\"/\", n=6, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Image = \"../data/cspine_hardware/new_extract/\" + split[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = compare_df.rename(columns={\"png_path\": \"Image\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13287"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19118"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = data_df.merge(compare_df, on='Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df.drop_duplicates(subset=\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10729"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[data_df.Race.isin(['African American  or Black', 'Caucasian or White'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10358"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df.EMPI.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caucasian or White            7589\n",
       "African American  or Black    2769\n",
       "Name: Race, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.Race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caucasian or White            0.73267\n",
       "African American  or Black    0.26733\n",
       "Name: Race, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.Race.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F    5488\n",
       "M    4870\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train       0.805947\n",
       "validate    0.102819\n",
       "test        0.091234\n",
       "Name: split, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.rename(columns={\"split_x\": \"split\"})\n",
    "data_df.split.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Image = data_df.Image.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 320, 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34, preprocess_input = Classifiers.get('resnet34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "base_model = resnet34(input_tensor=input_a, include_top=False, input_shape=(HEIGHT,WIDTH,3), weights='imagenet')\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dense(2, name='dense_logits')(x)\n",
    "output = layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "model = Model(inputs=[input_a], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "decay_val= 0.0 \n",
    "batch_s = 256\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1,\n",
    "                              patience=2, min_lr=1e-5, verbose=1)\n",
    "\n",
    "adam_opt = optimizers.Adam(learning_rate=learning_rate, decay=decay_val)\n",
    "\n",
    "model.compile(optimizer=adam_opt,\n",
    "                loss=tf.losses.CategoricalCrossentropy(name='loss'),\n",
    "                metrics=[\n",
    "                    tf.keras.metrics.AUC(curve='ROC', name='ROC-AUC')\n",
    "                ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            fill_mode='constant',\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "validate_gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = batch_s\n",
    "test_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_df[data_df.split==\"train\"]\n",
    "validate_df = data_df[data_df.split==\"validate\"]\n",
    "test_df = data_df[data_df.split==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8346 validated image filenames belonging to 2 classes.\n",
      "Found 1065 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-brandon/.local/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 2 invalid image filename(s) in x_col=\"Image\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_gen.flow_from_dataframe(train_df, x_col=\"Image\", y_col=\"Race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=True,seed=2021,batch_size=train_batch_size, dtype='float32')\n",
    "\n",
    "validate_batches = validate_gen.flow_from_dataframe(validate_df, x_col=\"Image\", y_col=\"Race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_name = \"resnet34_cspine_race_detection_with_random_seed_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = math.ceil(len(train_df) / batch_s)\n",
    "val_epoch = math.ceil(len(validate_df) / test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_date = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "ES = EarlyStopping(monitor='val_loss', mode='min', patience=4, restore_best_weights=True)\n",
    "checkloss = ModelCheckpoint(\"../saved_models/\" + str(arc_name) + \"_CXR_\" +var_date+\"_epoch:{epoch:03d}_val_loss:{val_loss:.5f}.hdf5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/33 [============================>.] - ETA: 10s - loss: 0.6883 - ROC-AUC: 0.7275\n",
      "Epoch 00001: val_loss improved from inf to 8.61255, saving model to ../saved_models/resnet34_cspine_race_detection_with_random_seed__CXR_20210627-212707_epoch:001_val_loss:8.61255.hdf5\n",
      "33/33 [==============================] - 454s 14s/step - loss: 0.6849 - ROC-AUC: 0.7281 - val_loss: 8.6126 - val_ROC-AUC: 0.3036\n",
      "Epoch 2/100\n",
      "32/33 [============================>.] - ETA: 9s - loss: 0.5373 - ROC-AUC: 0.8061 \n",
      "Epoch 00002: val_loss improved from 8.61255 to 2.10922, saving model to ../saved_models/resnet34_cspine_race_detection_with_random_seed__CXR_20210627-212707_epoch:002_val_loss:2.10922.hdf5\n",
      "33/33 [==============================] - 340s 10s/step - loss: 0.5358 - ROC-AUC: 0.8075 - val_loss: 2.1092 - val_ROC-AUC: 0.3446\n",
      "Epoch 3/100\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.4154 - ROC-AUC: 0.8911\n",
      "Epoch 00003: val_loss improved from 2.10922 to 0.82805, saving model to ../saved_models/resnet34_cspine_race_detection_with_random_seed__CXR_20210627-212707_epoch:003_val_loss:0.82805.hdf5\n",
      "33/33 [==============================] - 147s 4s/step - loss: 0.4144 - ROC-AUC: 0.8917 - val_loss: 0.8280 - val_ROC-AUC: 0.8110\n",
      "Epoch 4/100\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.3202 - ROC-AUC: 0.9370\n",
      "Epoch 00004: val_loss improved from 0.82805 to 0.68681, saving model to ../saved_models/resnet34_cspine_race_detection_with_random_seed__CXR_20210627-212707_epoch:004_val_loss:0.68681.hdf5\n",
      "33/33 [==============================] - 131s 4s/step - loss: 0.3192 - ROC-AUC: 0.9374 - val_loss: 0.6868 - val_ROC-AUC: 0.8475\n",
      "Epoch 5/100\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.2590 - ROC-AUC: 0.9589\n",
      "Epoch 00005: val_loss did not improve from 0.68681\n",
      "33/33 [==============================] - 131s 4s/step - loss: 0.2574 - ROC-AUC: 0.9594 - val_loss: 1.3166 - val_ROC-AUC: 0.7579\n",
      "Epoch 6/100\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.2043 - ROC-AUC: 0.9746\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.68681\n",
      "33/33 [==============================] - 127s 4s/step - loss: 0.2036 - ROC-AUC: 0.9748 - val_loss: 1.7914 - val_ROC-AUC: 0.5367\n",
      "Epoch 7/100\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.1354 - ROC-AUC: 0.9895\n",
      "Epoch 00007: val_loss improved from 0.68681 to 0.42511, saving model to ../saved_models/resnet34_cspine_race_detection_with_random_seed__CXR_20210627-212707_epoch:007_val_loss:0.42511.hdf5\n",
      "33/33 [==============================] - 132s 4s/step - loss: 0.1356 - ROC-AUC: 0.9894 - val_loss: 0.4251 - val_ROC-AUC: 0.9272\n",
      "Epoch 8/100\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.0934 - ROC-AUC: 0.9950\n",
      "Epoch 00008: val_loss improved from 0.42511 to 0.39056, saving model to ../saved_models/resnet34_cspine_race_detection_with_random_seed__CXR_20210627-212707_epoch:008_val_loss:0.39056.hdf5\n",
      "33/33 [==============================] - 135s 4s/step - loss: 0.0929 - ROC-AUC: 0.9951 - val_loss: 0.3906 - val_ROC-AUC: 0.9422\n",
      "Epoch 9/100\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.0814 - ROC-AUC: 0.9958\n",
      "Epoch 00009: val_loss did not improve from 0.39056\n",
      "33/33 [==============================] - 123s 4s/step - loss: 0.0816 - ROC-AUC: 0.9958 - val_loss: 0.5122 - val_ROC-AUC: 0.9357\n",
      "Epoch 10/100\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.0679 - ROC-AUC: 0.9970\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.39056\n",
      "33/33 [==============================] - 122s 4s/step - loss: 0.0684 - ROC-AUC: 0.9969 - val_loss: 0.5492 - val_ROC-AUC: 0.9314\n",
      "Epoch 11/100\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.0569 - ROC-AUC: 0.9979\n",
      "Epoch 00011: val_loss did not improve from 0.39056\n",
      "33/33 [==============================] - 123s 4s/step - loss: 0.0573 - ROC-AUC: 0.9979 - val_loss: 0.4744 - val_ROC-AUC: 0.9420\n",
      "Epoch 12/100\n",
      "32/33 [============================>.] - ETA: 3s - loss: 0.0549 - ROC-AUC: 0.9982\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.39056\n",
      "33/33 [==============================] - 119s 4s/step - loss: 0.0543 - ROC-AUC: 0.9983 - val_loss: 0.4206 - val_ROC-AUC: 0.9482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8c9a7e5438>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_batches, \n",
    "    steps_per_epoch=train_epoch, \n",
    "    epochs=100, \n",
    "    callbacks=[reduce_lr, checkloss, ES],\n",
    "    validation_data=validate_batches, \n",
    "    validation_steps=val_epoch, \n",
    "    max_queue_size=10,\n",
    "    workers=32,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 945 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = validate_gen.flow_from_dataframe(test_df, x_col=\"Image\", y_col=\"Race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caucasian or White            0.697354\n",
       "African American  or Black    0.302646\n",
       "Name: Race, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Race.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 300s 20s/step\n"
     ]
    }
   ],
   "source": [
    "race_multilabel_predict_test = model.predict(test_batches, max_queue_size=10, verbose=1, steps=math.ceil(len(test_df)/test_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_input_prediction = race_multilabel_predict_test\n",
    "input_df = test_df\n",
    "race_input_prediction_df = pd.DataFrame(race_input_prediction)\n",
    "race_true_logits = pd.DataFrame()\n",
    "race_loss_log = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_calc(input_prediction_df, input_df):\n",
    "    ground_truth = input_df.Race\n",
    "    #ground_truth = ground_truth.apply(', '.join)\n",
    "    pathology_array=[\n",
    "        'African American  or Black',\n",
    "        'Caucasian or White'\n",
    "        ]\n",
    "\n",
    "    i=0\n",
    "    auc_array = []\n",
    "    for pathology in pathology_array:\n",
    "        \n",
    "        new_truth = (ground_truth.str.contains(pathology)).apply(int)\n",
    "        input_prediction_val = input_prediction_df[i]\n",
    "        val = input_prediction_val\n",
    "        AUC = roc_auc_score(new_truth, val)\n",
    "        race_true_logits.insert(i, i, new_truth, True)\n",
    "        auc_array.append(AUC)\n",
    "        i += 1\n",
    "        \n",
    "    progress_df = pd.DataFrame({'Study':pathology_array, 'AUC':auc_array})\n",
    "    print(progress_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Study       AUC\n",
      "0  African American  or Black  0.919251\n",
      "1          Caucasian or White  0.919251\n"
     ]
    }
   ],
   "source": [
    "stat_calc(race_input_prediction_df, input_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
