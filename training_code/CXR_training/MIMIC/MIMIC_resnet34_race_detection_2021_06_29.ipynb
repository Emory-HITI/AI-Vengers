{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, accuracy_score, recall_score, precision_score, f1_score\n",
    "import random as python_random\n",
    "\n",
    "#pip install image-classifiers==1.0.0b1\n",
    "from classification_models.tfkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(2021)\n",
    "python_random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:51: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(mirrored_strategy.num_replicas_in_sync))\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('modified_viewposition_race_4-race-ethnicity_60-10-30_split_with_gender_age_ver_b.csv')\n",
    "data_df = data_df[data_df.race.isin(['WHITE','BLACK/AFRICAN AMERICAN','ASIAN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train       0.598783\n",
       "test        0.301700\n",
       "validate    0.099517\n",
       "Name: split, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.split.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                     0.775148\n",
       "BLACK/AFRICAN AMERICAN    0.186701\n",
       "ASIAN                     0.038151\n",
       "Name: race, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.race.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.subject_id = data_df.subject_id.astype(str)\n",
    "data_df.study_id = data_df.study_id.astype(str)\n",
    "data_df = data_df.fillna(0)\n",
    "data_df.insert(2, \"path\", \"\")\n",
    "data_df.path = data_df.subject_id.str[0:2]\n",
    "data_df.path = \"p\" + data_df.path\n",
    "data_df.path = data_df.path + \"/p\" + data_df.subject_id + \"/s\" + data_df.study_id + \"/\" + data_df.dicom_id + \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_df[data_df.split==\"train\"]\n",
    "validation_df = data_df[data_df.split==\"validate\"]\n",
    "test_df = data_df[data_df.split==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False indicates no patient_id shared between groups\n",
    "\n",
    "unique_train_id = train_df.subject_id.unique()\n",
    "unique_validation_id = validation_df.subject_id.unique()\n",
    "unique_test_id = test_df.subject_id.unique()\n",
    "all_id = np.concatenate((unique_train_id, unique_validation_id, unique_test_id), axis=None)\n",
    "\n",
    "def contains_duplicates(X):\n",
    "    return len(np.unique(X)) != len(X)\n",
    "\n",
    "contains_duplicates(all_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 320, 320\n",
    "\n",
    "arc_name = \"MIMIC-\" + str(HEIGHT) + \"x\" + str(WIDTH) + \"60-10-30-split-resnet-Float16_3-race_detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34, preprocess_input = Classifiers.get('resnet34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    input_a = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    base_model = resnet34(input_tensor=input_a, include_top=False, input_shape=(HEIGHT,WIDTH,3), weights='imagenet')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(3, name='dense_logits')(x)\n",
    "    output = Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "    model = Model(inputs=[input_a], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "momentum_val=0.9\n",
    "decay_val= 0.0\n",
    "batch_s = 256 # may need to reduce batch size if OOM error occurs\n",
    "train_batch_size = batch_s\n",
    "test_batch_size = 256\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=2, min_lr=1e-5, verbose=1)\n",
    "\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=learning_rate, decay=decay_val)\n",
    "adam_opt = tf.keras.mixed_precision.LossScaleOptimizer(adam_opt)\n",
    "\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    model.compile(optimizer=adam_opt,\n",
    "                    loss=tf.losses.CategoricalCrossentropy(),\n",
    "                    metrics=[\n",
    "                        tf.keras.metrics.AUC(curve='ROC', name='ROC-AUC'),\n",
    "                        tf.keras.metrics.AUC(curve='PR', name='PR-AUC')\n",
    "                    ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            fill_mode='constant',\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.1,\n",
    "            preprocessing_function=preprocess_input\n",
    "            )\n",
    "\n",
    "validate_gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 116331 validated image filenames belonging to 3 classes.\n",
      "Found 19334 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_gen.flow_from_dataframe(train_df, directory=\"/tf/notebooks/SSD_data/mimic_directory/files\", x_col=\"path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=True,seed=2021,batch_size=train_batch_size, dtype='float32')\n",
    "validate_batches = validate_gen.flow_from_dataframe(validation_df, directory=\"/tf/notebooks/SSD_data/mimic_directory/files\", x_col=\"path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = math.ceil(len(train_df) / train_batch_size)\n",
    "val_epoch = math.ceil(len(validation_df) / test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_date = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "ES = EarlyStopping(monitor='val_loss', mode='min', patience=4, restore_best_weights=True)\n",
    "checkloss = ModelCheckpoint(\"../saved_models/racial_bias/trials/\" + str(arc_name) + \"_CXR_LR-\" + str(learning_rate) + \"_\" + var_date+\"_epoch:{epoch:03d}_val_loss:{val_loss:.5f}.hdf5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 108 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 108 all-reduces with algorithm = nccl, num_packs = 1\n",
      "455/455 [==============================] - 756s 1s/step - loss: 0.3512 - ROC-AUC: 0.9656 - PR-AUC: 0.9394 - val_loss: 0.3471 - val_ROC-AUC: 0.9672 - val_PR-AUC: 0.9414\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.34711, saving model to ../saved_models/racial_bias/trials/MIMIC-320x32060-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210628-011052_epoch:001_val_loss:0.34711.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "455/455 [==============================] - 724s 2s/step - loss: 0.2392 - ROC-AUC: 0.9831 - PR-AUC: 0.9695 - val_loss: 0.4755 - val_ROC-AUC: 0.9425 - val_PR-AUC: 0.8959\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.34711\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 724s 2s/step - loss: 0.2044 - ROC-AUC: 0.9874 - PR-AUC: 0.9770 - val_loss: 0.2485 - val_ROC-AUC: 0.9820 - val_PR-AUC: 0.9680\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.34711 to 0.24853, saving model to ../saved_models/racial_bias/trials/MIMIC-320x32060-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210628-011052_epoch:003_val_loss:0.24853.hdf5\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 729s 2s/step - loss: 0.1828 - ROC-AUC: 0.9896 - PR-AUC: 0.9810 - val_loss: 0.3081 - val_ROC-AUC: 0.9735 - val_PR-AUC: 0.9520\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24853\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 727s 2s/step - loss: 0.1670 - ROC-AUC: 0.9912 - PR-AUC: 0.9839 - val_loss: 0.3777 - val_ROC-AUC: 0.9626 - val_PR-AUC: 0.9334\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24853\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 726s 2s/step - loss: 0.1212 - ROC-AUC: 0.9950 - PR-AUC: 0.9907 - val_loss: 0.1784 - val_ROC-AUC: 0.9897 - val_PR-AUC: 0.9809\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.24853 to 0.17844, saving model to ../saved_models/racial_bias/trials/MIMIC-320x32060-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210628-011052_epoch:006_val_loss:0.17844.hdf5\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 718s 2s/step - loss: 0.1047 - ROC-AUC: 0.9959 - PR-AUC: 0.9923 - val_loss: 0.1799 - val_ROC-AUC: 0.9897 - val_PR-AUC: 0.9806\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.17844\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 720s 2s/step - loss: 0.0975 - ROC-AUC: 0.9964 - PR-AUC: 0.9932 - val_loss: 0.1663 - val_ROC-AUC: 0.9905 - val_PR-AUC: 0.9823\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.17844 to 0.16625, saving model to ../saved_models/racial_bias/trials/MIMIC-320x32060-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210628-011052_epoch:008_val_loss:0.16625.hdf5\n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 727s 2s/step - loss: 0.0913 - ROC-AUC: 0.9967 - PR-AUC: 0.9937 - val_loss: 0.1975 - val_ROC-AUC: 0.9879 - val_PR-AUC: 0.9772\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16625\n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 730s 2s/step - loss: 0.0883 - ROC-AUC: 0.9968 - PR-AUC: 0.9941 - val_loss: 0.2009 - val_ROC-AUC: 0.9881 - val_PR-AUC: 0.9779\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16625\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 720s 2s/step - loss: 0.0763 - ROC-AUC: 0.9976 - PR-AUC: 0.9954 - val_loss: 0.1864 - val_ROC-AUC: 0.9889 - val_PR-AUC: 0.9792\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16625\n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 725s 2s/step - loss: 0.0751 - ROC-AUC: 0.9976 - PR-AUC: 0.9955 - val_loss: 0.1886 - val_ROC-AUC: 0.9887 - val_PR-AUC: 0.9786\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16625\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f52784cbc18>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_batches,\n",
    "            validation_data=validate_batches,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=int(train_epoch),\n",
    "            validation_steps=int(val_epoch),\n",
    "            workers=32,\n",
    "            max_queue_size=50,\n",
    "            shuffle=True,\n",
    "            callbacks=[checkloss, reduce_lr, ES]\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                     0.780650\n",
       "BLACK/AFRICAN AMERICAN    0.181475\n",
       "ASIAN                     0.037875\n",
       "Name: race, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.race.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58614 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = validate_gen.flow_from_dataframe(test_df, directory=\"/tf/notebooks/SSD_data/mimic_directory/files\", x_col=\"path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 343s 1s/step\n"
     ]
    }
   ],
   "source": [
    "with mirrored_strategy.scope():\n",
    "\n",
    "    multilabel_predict_test = model.predict(test_batches, max_queue_size=10, verbose=1, steps=math.ceil(len(test_df)/test_batch_size), workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prediction = multilabel_predict_test\n",
    "input_df = test_df\n",
    "input_prediction_df = pd.DataFrame(input_prediction)\n",
    "true_logits = pd.DataFrame()\n",
    "loss_log = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_calc(input_prediction_df, input_df):\n",
    "    ground_truth = input_df.race\n",
    "    pathology_array=[\n",
    "        'ASIAN',\n",
    "        'BLACK/AFRICAN AMERICAN',\n",
    "        'WHITE'\n",
    "        ]\n",
    "    i=0\n",
    "    auc_array = []\n",
    "    for pathology in pathology_array:\n",
    "    \n",
    "        new_truth = (ground_truth.str.contains(pathology)).apply(int)\n",
    "        input_prediction_val = input_prediction_df[i]\n",
    "        val = input_prediction_val\n",
    "        AUC = roc_auc_score(new_truth, val)\n",
    "        true_logits.insert(i, i, new_truth, True)\n",
    "        auc_array.append(AUC)\n",
    "        i += 1\n",
    "        \n",
    "    progress_df = pd.DataFrame({'Study':pathology_array, 'AUC':auc_array})\n",
    "    print(progress_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Study       AUC\n",
      "0                   ASIAN  0.979197\n",
      "1  BLACK/AFRICAN AMERICAN  0.974881\n",
      "2                   WHITE  0.973417\n"
     ]
    }
   ],
   "source": [
    "stat_calc(input_prediction_df, input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
