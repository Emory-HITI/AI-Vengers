{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, accuracy_score, recall_score, precision_score, f1_score\n",
    "import random as python_random\n",
    "\n",
    "#pip install image-classifiers==1.0.0b1\n",
    "from classification_models.tfkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(2021)\n",
    "python_random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:51: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(mirrored_strategy.num_replicas_in_sync))\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('2021_04_04_asian-black-white-chexpert_ver_A.csv')\n",
    "data_df = data_df[data_df.ETHNICITY==\"Non-Hispanic/Non-Latino\"]\n",
    "data_df = data_df[data_df.Position.isin(['AP','PA'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train       0.601337\n",
       "test        0.302002\n",
       "validate    0.096660\n",
       "Name: split, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.split.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                     0.779041\n",
       "ASIAN                     0.148145\n",
       "BLACK/AFRICAN AMERICAN    0.072814\n",
       "Name: race, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.race.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_df[data_df.split==\"train\"]\n",
    "validation_df = data_df[data_df.split==\"validate\"]\n",
    "test_df = data_df[data_df.split==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False indicates no patient_id shared between groups\n",
    "\n",
    "unique_train_id = train_df.patient_id.unique()\n",
    "unique_validation_id = validation_df.patient_id.unique()\n",
    "unique_test_id = test_df.patient_id.unique()\n",
    "all_id = np.concatenate((unique_train_id, unique_validation_id, unique_test_id), axis=None)\n",
    "\n",
    "def contains_duplicates(X):\n",
    "    return len(np.unique(X)) != len(X)\n",
    "\n",
    "contains_duplicates(all_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 320, 320\n",
    "\n",
    "arc_name = \"CHEXPERT-\" + str(HEIGHT) + \"x\" + str(WIDTH) + \"_60-10-30-split-resnet34-Float16_3-race_detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34, preprocess_input = Classifiers.get('resnet34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    input_a = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    base_model = resnet34(input_tensor=input_a, include_top=False, input_shape=(HEIGHT,WIDTH,3), weights='imagenet')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(3, name='dense_logits')(x)\n",
    "    output = Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "    model = Model(inputs=[input_a], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "momentum_val=0.9\n",
    "decay_val= 0.0\n",
    "train_batch_size = 256 # may need to reduce batch size if OOM error occurs\n",
    "test_batch_size = 256\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=2, min_lr=1e-5, verbose=1)\n",
    "\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=learning_rate, decay=decay_val)\n",
    "adam_opt = tf.keras.mixed_precision.LossScaleOptimizer(adam_opt)\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    model.compile(optimizer=adam_opt,\n",
    "                    loss=tf.losses.CategoricalCrossentropy(),\n",
    "                    metrics=[\n",
    "                        tf.keras.metrics.AUC(curve='ROC', name='ROC-AUC'),\n",
    "                        tf.keras.metrics.AUC(curve='PR', name='PR-AUC')\n",
    "                    ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            fill_mode='constant',\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.1,\n",
    "            preprocessing_function=preprocess_input\n",
    "            )\n",
    "\n",
    "validate_gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76433 validated image filenames belonging to 3 classes.\n",
      "Found 12286 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_gen.flow_from_dataframe(train_df, directory=\"/tf/notebooks/SSD_data/chexpert_directory/\", x_col=\"Path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=True,seed=2021,batch_size=train_batch_size, dtype='float32')\n",
    "validate_batches = validate_gen.flow_from_dataframe(validation_df, directory=\"/tf/notebooks/SSD_data/chexpert_directory/\", x_col=\"Path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = math.ceil(len(train_df) / train_batch_size)\n",
    "val_epoch = math.ceil(len(validation_df) / test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_date = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "ES = EarlyStopping(monitor='val_loss', mode='min', patience=4, restore_best_weights=True)\n",
    "checkloss = ModelCheckpoint(\"../saved_models/racial_bias/trials/\" + str(arc_name) + \"_CXR_LR-\" + str(learning_rate) + \"_\" + var_date+\"_epoch:{epoch:03d}_val_loss:{val_loss:.5f}.hdf5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 108 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 108 all-reduces with algorithm = nccl, num_packs = 1\n",
      "299/299 [==============================] - 781s 2s/step - loss: 0.4739 - ROC-AUC: 0.9392 - PR-AUC: 0.8933 - val_loss: 3.5495 - val_ROC-AUC: 0.4986 - val_PR-AUC: 0.3073\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.54947, saving model to ../saved_models/racial_bias/trials/CHEXPERT-320x320_60-10-30-split-resnet34-Float16_3-race_detection_CXR_LR-0.001_20210627-134953_epoch:001_val_loss:3.54947.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "299/299 [==============================] - 594s 2s/step - loss: 0.3289 - ROC-AUC: 0.9697 - PR-AUC: 0.9454 - val_loss: 0.3562 - val_ROC-AUC: 0.9683 - val_PR-AUC: 0.9446\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.54947 to 0.35616, saving model to ../saved_models/racial_bias/trials/CHEXPERT-320x320_60-10-30-split-resnet34-Float16_3-race_detection_CXR_LR-0.001_20210627-134953_epoch:002_val_loss:0.35616.hdf5\n",
      "Epoch 3/100\n",
      "299/299 [==============================] - 563s 2s/step - loss: 0.2811 - ROC-AUC: 0.9774 - PR-AUC: 0.9588 - val_loss: 0.3598 - val_ROC-AUC: 0.9701 - val_PR-AUC: 0.9477\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.35616\n",
      "Epoch 4/100\n",
      "299/299 [==============================] - 555s 2s/step - loss: 0.2530 - ROC-AUC: 0.9813 - PR-AUC: 0.9660 - val_loss: 0.3989 - val_ROC-AUC: 0.9611 - val_PR-AUC: 0.9338\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.35616\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/100\n",
      "299/299 [==============================] - 557s 2s/step - loss: 0.1922 - ROC-AUC: 0.9884 - PR-AUC: 0.9786 - val_loss: 0.2415 - val_ROC-AUC: 0.9837 - val_PR-AUC: 0.9713\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35616 to 0.24155, saving model to ../saved_models/racial_bias/trials/CHEXPERT-320x320_60-10-30-split-resnet34-Float16_3-race_detection_CXR_LR-0.001_20210627-134953_epoch:005_val_loss:0.24155.hdf5\n",
      "Epoch 6/100\n",
      "299/299 [==============================] - 563s 2s/step - loss: 0.1756 - ROC-AUC: 0.9900 - PR-AUC: 0.9816 - val_loss: 0.2740 - val_ROC-AUC: 0.9798 - val_PR-AUC: 0.9656\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24155\n",
      "Epoch 7/100\n",
      "299/299 [==============================] - 568s 2s/step - loss: 0.1680 - ROC-AUC: 0.9909 - PR-AUC: 0.9829 - val_loss: 0.2241 - val_ROC-AUC: 0.9858 - val_PR-AUC: 0.9746\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24155 to 0.22415, saving model to ../saved_models/racial_bias/trials/CHEXPERT-320x320_60-10-30-split-resnet34-Float16_3-race_detection_CXR_LR-0.001_20210627-134953_epoch:007_val_loss:0.22415.hdf5\n",
      "Epoch 8/100\n",
      "299/299 [==============================] - 557s 2s/step - loss: 0.1611 - ROC-AUC: 0.9915 - PR-AUC: 0.9841 - val_loss: 0.2297 - val_ROC-AUC: 0.9850 - val_PR-AUC: 0.9732\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.22415\n",
      "Epoch 9/100\n",
      "299/299 [==============================] - 559s 2s/step - loss: 0.1548 - ROC-AUC: 0.9920 - PR-AUC: 0.9848 - val_loss: 0.2381 - val_ROC-AUC: 0.9839 - val_PR-AUC: 0.9711\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.22415\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/100\n",
      "299/299 [==============================] - 553s 2s/step - loss: 0.1426 - ROC-AUC: 0.9931 - PR-AUC: 0.9869 - val_loss: 0.2325 - val_ROC-AUC: 0.9849 - val_PR-AUC: 0.9732\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.22415\n",
      "Epoch 11/100\n",
      "299/299 [==============================] - 560s 2s/step - loss: 0.1388 - ROC-AUC: 0.9933 - PR-AUC: 0.9874 - val_loss: 0.2281 - val_ROC-AUC: 0.9854 - val_PR-AUC: 0.9743\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.22415\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b346caba8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_batches,\n",
    "            validation_data=validate_batches,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=int(train_epoch),\n",
    "            validation_steps=int(val_epoch),\n",
    "            workers=32,\n",
    "            max_queue_size=50,\n",
    "            shuffle=False,\n",
    "            callbacks=[checkloss, reduce_lr, ES]\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38386 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = validate_gen.flow_from_dataframe(test_df, directory=\"/tf/notebooks/fishtank/radiology_datasets/CheXpert_Xray_dataset/resize_chexpert_320x320/chexpert_data/\", x_col=\"Path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 134s 873ms/step\n"
     ]
    }
   ],
   "source": [
    "with mirrored_strategy.scope():\n",
    "\n",
    "    multilabel_predict_test = model.predict(test_batches, max_queue_size=10, verbose=1, steps=math.ceil(len(test_df)/test_batch_size), workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prediction = multilabel_predict_test\n",
    "input_df = test_df\n",
    "input_prediction_df = pd.DataFrame(input_prediction)\n",
    "true_logits = pd.DataFrame()\n",
    "loss_log = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_calc(input_prediction_df, input_df):\n",
    "    ground_truth = input_df.race\n",
    "    pathology_array=[\n",
    "        'ASIAN',\n",
    "        'BLACK/AFRICAN AMERICAN',\n",
    "        'WHITE'\n",
    "        ]\n",
    "    i=0\n",
    "    auc_array = []\n",
    "    for pathology in pathology_array:\n",
    "    \n",
    "        new_truth = (ground_truth.str.contains(pathology)).apply(int)\n",
    "        input_prediction_val = input_prediction_df[i]\n",
    "        val = input_prediction_val\n",
    "        AUC = roc_auc_score(new_truth, val)\n",
    "        true_logits.insert(i, i, new_truth, True)\n",
    "        auc_array.append(AUC)\n",
    "        i += 1\n",
    "        \n",
    "    progress_df = pd.DataFrame({'Study':pathology_array, 'AUC':auc_array})\n",
    "    print(progress_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Study       AUC\n",
      "0                   ASIAN  0.970054\n",
      "1  BLACK/AFRICAN AMERICAN  0.967394\n",
      "2                   WHITE  0.966309\n"
     ]
    }
   ],
   "source": [
    "stat_calc(input_prediction_df, input_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
