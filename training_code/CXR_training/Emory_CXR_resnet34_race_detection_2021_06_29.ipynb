{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import math\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, matthews_corrcoef, auc, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate, add, GlobalAveragePooling2D, BatchNormalization, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from classification_models.tfkeras import Classifiers\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import ImageFile\n",
    "import random as python_random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(2021)\n",
    "python_random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_censored.csv')\n",
    "validate_df = pd.read_csv('val_censored.csv')\n",
    "test_df = pd.read_csv('test_censored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.Race.isin(['ASIAN','BLACK/AFRICAN AMERICAN','WHITE'])]\n",
    "validate_df = validate_df[validate_df.Race.isin(['ASIAN','BLACK/AFRICAN AMERICAN','WHITE'])]\n",
    "test_df = test_df[test_df.Race.isin(['ASIAN','BLACK/AFRICAN AMERICAN','WHITE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.hiti_path = train_df.hiti_path.astype(str)\n",
    "validate_df.hiti_path = validate_df.hiti_path.astype(str)\n",
    "test_df.hiti_path = test_df.hiti_path.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184974"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove 0 byte images\n",
    "validate_df = validate_df[~validate_df.hiti_path.str.contains('406e0996e5f1cf082487d7d096574d10b46c0c52710222a4884db1cc|dd97e997cc2a4166dc6e192cb62e29553aa28f4671d98c9577e32cfd|6224290209c45bb2b3e07b3b3a27778d1d10f7953567b3c59158e099')]\n",
    "test_df = test_df[~test_df.hiti_path.str.contains('406e0996e5f1cf082487d7d096574d10b46c0c52710222a4884db1cc|dd97e997cc2a4166dc6e192cb62e29553aa28f4671d98c9577e32cfd|6224290209c45bb2b3e07b3b3a27778d1d10f7953567b3c59158e099')]\n",
    "train_df = train_df[~train_df.hiti_path.str.contains('406e0996e5f1cf082487d7d096574d10b46c0c52710222a4884db1cc|dd97e997cc2a4166dc6e192cb62e29553aa28f4671d98c9577e32cfd|6224290209c45bb2b3e07b3b3a27778d1d10f7953567b3c59158e099')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                     91369\n",
       "BLACK/AFRICAN AMERICAN    87139\n",
       "ASIAN                      6457\n",
       "Name: Race, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLACK/AFRICAN AMERICAN    7540\n",
       "WHITE                     6656\n",
       "ASIAN                      530\n",
       "Name: Race, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df.Race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLACK/AFRICAN AMERICAN    6067\n",
       "WHITE                     5281\n",
       "ASIAN                      484\n",
       "Name: Race, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 320, 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_name = \"Emory_CXR-\" + str(HEIGHT) + \"x\" + str(WIDTH) + \"resnet34-Float32_3-race_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34, preprocess_input = Classifiers.get('resnet34')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "base_model = resnet34(input_tensor=input_a, include_top=False, input_shape=(HEIGHT,WIDTH,3), weights='imagenet')\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dense(3, name='dense_logits')(x)\n",
    "output = layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "model = Model(inputs=[input_a], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "decay_val= 0.0\n",
    "batch_s = 256\n",
    "desired_epoch = 3\n",
    "train_batch_size = batch_s\n",
    "test_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1,\n",
    "                              patience=2, min_lr=1e-5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_opt = optimizers.Adam(lr=learning_rate, decay=decay_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam_opt,\n",
    "                loss=tf.losses.CategoricalCrossentropy(),\n",
    "                metrics=[\n",
    "                    tf.keras.metrics.AUC(curve='ROC', name='ROC-AUC'),\n",
    "                    tf.keras.metrics.AUC(curve='PR', name='PR-AUC')\n",
    "                ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "            rotation_range=15, \n",
    "            fill_mode='constant',\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.1,\n",
    "            preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "validate_gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 184965 validated image filenames belonging to 3 classes.\n",
      "Found 14726 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_gen.flow_from_dataframe(train_df, x_col=\"hiti_path\", y_col=\"Race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=True,seed=2021,batch_size=train_batch_size, dtype='float32')\n",
    "\n",
    "validate_batches = validate_gen.flow_from_dataframe(validate_df,x_col=\"hiti_path\", y_col=\"Race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = math.ceil(len(train_df) / train_batch_size)\n",
    "val_epoch = math.ceil(len(validate_df) / test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_date = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "ES = EarlyStopping(monitor='val_loss', mode='min', patience=4, restore_best_weights=True)\n",
    "checkloss = ModelCheckpoint(\"../saved_models/\" + str(arc_name) + \"_LR-\" + str(learning_rate) + \"_\" + var_date+\"_epoch:{epoch:03d}_val_loss:{val_loss:.5f}.hdf5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "722/723 [============================>.] - ETA: 12s - loss: 0.4047 - ROC-AUC: 0.9553 - PR-AUC: 0.9212\n",
      "Epoch 00001: val_loss improved from inf to 0.30497, saving model to ../saved_models/Emory_CXR-320x320resnet34-Float32_3-race__LR-0.001_20210627-214820_epoch:001_val_loss:0.30497.hdf5\n",
      "723/723 [==============================] - 10084s 14s/step - loss: 0.4045 - ROC-AUC: 0.9553 - PR-AUC: 0.9213 - val_loss: 0.3050 - val_ROC-AUC: 0.9739 - val_PR-AUC: 0.9548\n",
      "Epoch 2/100\n",
      "722/723 [============================>.] - ETA: 11s - loss: 0.2760 - ROC-AUC: 0.9784 - PR-AUC: 0.9613\n",
      "Epoch 00002: val_loss improved from 0.30497 to 0.22691, saving model to ../saved_models/Emory_CXR-320x320resnet34-Float32_3-race__LR-0.001_20210627-214820_epoch:002_val_loss:0.22691.hdf5\n",
      "723/723 [==============================] - 9132s 13s/step - loss: 0.2760 - ROC-AUC: 0.9784 - PR-AUC: 0.9613 - val_loss: 0.2269 - val_ROC-AUC: 0.9853 - val_PR-AUC: 0.9739\n",
      "Epoch 3/100\n",
      "722/723 [============================>.] - ETA: 11s - loss: 0.2413 - ROC-AUC: 0.9832 - PR-AUC: 0.9696\n",
      "Epoch 00003: val_loss did not improve from 0.22691\n",
      "723/723 [==============================] - 9356s 13s/step - loss: 0.2413 - ROC-AUC: 0.9832 - PR-AUC: 0.9696 - val_loss: 0.2996 - val_ROC-AUC: 0.9760 - val_PR-AUC: 0.9574\n",
      "Epoch 4/100\n",
      "722/723 [============================>.] - ETA: 10s - loss: 0.2202 - ROC-AUC: 0.9857 - PR-AUC: 0.9741\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22691\n",
      "723/723 [==============================] - 8650s 12s/step - loss: 0.2202 - ROC-AUC: 0.9858 - PR-AUC: 0.9741 - val_loss: 0.2553 - val_ROC-AUC: 0.9821 - val_PR-AUC: 0.9687\n",
      "Epoch 5/100\n",
      "722/723 [============================>.] - ETA: 12s - loss: 0.1675 - ROC-AUC: 0.9911 - PR-AUC: 0.9837\n",
      "Epoch 00005: val_loss improved from 0.22691 to 0.17858, saving model to ../saved_models/Emory_CXR-320x320resnet34-Float32_3-race__LR-0.001_20210627-214820_epoch:005_val_loss:0.17858.hdf5\n",
      "723/723 [==============================] - 9727s 13s/step - loss: 0.1675 - ROC-AUC: 0.9911 - PR-AUC: 0.9837 - val_loss: 0.1786 - val_ROC-AUC: 0.9902 - val_PR-AUC: 0.9826\n",
      "Epoch 6/100\n",
      "722/723 [============================>.] - ETA: 13s - loss: 0.1521 - ROC-AUC: 0.9925 - PR-AUC: 0.9861\n",
      "Epoch 00006: val_loss improved from 0.17858 to 0.16077, saving model to ../saved_models/Emory_CXR-320x320resnet34-Float32_3-race__LR-0.001_20210627-214820_epoch:006_val_loss:0.16077.hdf5\n",
      "723/723 [==============================] - 10374s 14s/step - loss: 0.1521 - ROC-AUC: 0.9925 - PR-AUC: 0.9861 - val_loss: 0.1608 - val_ROC-AUC: 0.9916 - val_PR-AUC: 0.9851\n",
      "Epoch 7/100\n",
      "722/723 [============================>.] - ETA: 13s - loss: 0.1443 - ROC-AUC: 0.9930 - PR-AUC: 0.9870\n",
      "Epoch 00007: val_loss did not improve from 0.16077\n",
      "723/723 [==============================] - 10532s 15s/step - loss: 0.1444 - ROC-AUC: 0.9930 - PR-AUC: 0.9870 - val_loss: 0.1687 - val_ROC-AUC: 0.9909 - val_PR-AUC: 0.9840\n",
      "Epoch 8/100\n",
      "722/723 [============================>.] - ETA: 9s - loss: 0.1390 - ROC-AUC: 0.9935 - PR-AUC: 0.9879 \n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16077\n",
      "723/723 [==============================] - 7289s 10s/step - loss: 0.1389 - ROC-AUC: 0.9935 - PR-AUC: 0.9879 - val_loss: 0.1789 - val_ROC-AUC: 0.9901 - val_PR-AUC: 0.9825\n",
      "Epoch 9/100\n",
      "722/723 [============================>.] - ETA: 8s - loss: 0.1294 - ROC-AUC: 0.9942 - PR-AUC: 0.9892 \n",
      "Epoch 00009: val_loss did not improve from 0.16077\n",
      "723/723 [==============================] - 6371s 9s/step - loss: 0.1294 - ROC-AUC: 0.9942 - PR-AUC: 0.9892 - val_loss: 0.1657 - val_ROC-AUC: 0.9913 - val_PR-AUC: 0.9846\n",
      "Epoch 10/100\n",
      "722/723 [============================>.] - ETA: 7s - loss: 0.1261 - ROC-AUC: 0.9944 - PR-AUC: 0.9896 \n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16077\n",
      "723/723 [==============================] - 6292s 9s/step - loss: 0.1262 - ROC-AUC: 0.9944 - PR-AUC: 0.9896 - val_loss: 0.1643 - val_ROC-AUC: 0.9914 - val_PR-AUC: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33992170f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_batches, \n",
    "    steps_per_epoch=train_epoch,\n",
    "    initial_epoch=0,\n",
    "    epochs=100, \n",
    "    verbose=1, \n",
    "    callbacks=[reduce_lr, checkloss, ES],\n",
    "    validation_data=validate_batches, \n",
    "    validation_steps=val_epoch, \n",
    "    validation_freq=1,\n",
    "    class_weight=None,\n",
    "    max_queue_size=10,\n",
    "    workers=32,\n",
    "    use_multiprocessing=False,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11832 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = validate_gen.flow_from_dataframe(test_df,x_col=\"hiti_path\", y_col=\"Race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1057s 3s/step\n"
     ]
    }
   ],
   "source": [
    "multilabel_predict_test = model.predict(test_batches, max_queue_size=10, verbose=1, steps=math.ceil(len(test_df)/test_batch_size), workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prediction = multilabel_predict_test\n",
    "input_df = test_df\n",
    "input_prediction_df = pd.DataFrame(input_prediction)\n",
    "true_logits = pd.DataFrame()\n",
    "loss_log = pd.DataFrame()\n",
    "#input_prediction_df = np.transpose(input_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_calc(input_prediction_df, input_df):\n",
    "    ground_truth = input_df.Race\n",
    "    #ground_truth = ground_truth.apply(', '.join)\n",
    "    pathology_array=[\n",
    "        'ASIAN',\n",
    "        'BLACK/AFRICAN AMERICAN',\n",
    "        'WHITE'\n",
    "        ]\n",
    "\n",
    "    i=0\n",
    "    auc_array = []\n",
    "    for pathology in pathology_array:\n",
    "        \n",
    "        new_truth = (ground_truth.str.contains(pathology)).apply(int)\n",
    "        input_prediction_val = input_prediction_df[i]\n",
    "        val = input_prediction_val\n",
    "        AUC = roc_auc_score(new_truth, val)\n",
    "        true_logits.insert(i, i, new_truth, True)\n",
    "        auc_array.append(AUC)\n",
    "        i += 1\n",
    "        \n",
    "    progress_df = pd.DataFrame({'Study':pathology_array, 'AUC':auc_array})\n",
    "    print(progress_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Study       AUC\n",
      "0                   ASIAN  0.969191\n",
      "1  BLACK/AFRICAN AMERICAN  0.992430\n",
      "2                   WHITE  0.987709\n"
     ]
    }
   ],
   "source": [
    "stat_calc(input_prediction_df, input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
