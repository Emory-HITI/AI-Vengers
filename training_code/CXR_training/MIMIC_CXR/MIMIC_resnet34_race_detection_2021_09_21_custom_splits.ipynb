{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model was made using a docker image\n",
    "# Docker image can be found at https://hub.docker.com/r/blackboxradiology/tf-2.6_with_pytorch\n",
    "# docker pull blackboxradiology/tf-2.6_with_pytorch\n",
    "\n",
    "# python version 3.6.9\n",
    "# mayplotlib version 3.3.4\n",
    "# numpy version 1.19.5\n",
    "# pandas version 1.1.5\n",
    "# PIL version 8.2.0\n",
    "# sklearn version 0.24.2\n",
    "# tensorflow version 2.6.0\n",
    "\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random as python_random\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import auc, accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "# pip install image-classifiers==1.0.0b1\n",
    "from classification_models.tfkeras import Classifiers\n",
    "# More information about this package can be found at https://github.com/qubvel/classification_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "python_random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/mixed_precision/loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "# All preprocessing steps of MIMIC .jpg images are included in this repository\n",
    "# Image data preprocessing include resizing to 320x320\n",
    "# and normalizing images with ImageNet mean and standard deviation values\n",
    "# using resnet34, preprocess_input = Classifiers.get('resnet34') from the classification_models.tfkeras package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>PerformedProcedureStepDescription</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>StudyTime</th>\n",
       "      <th>ProcedureCodeSequence_CodeMeaning</th>\n",
       "      <th>ViewCodeSequence_CodeMeaning</th>\n",
       "      <th>PatientOrientationCodeSequence_CodeMeaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dicom_id, subject_id, study_id, PerformedProcedureStepDescription, ViewPosition, Rows, Columns, StudyDate, StudyTime, ProcedureCodeSequence_CodeMeaning, ViewCodeSequence_CodeMeaning, PatientOrientationCodeSequence_CodeMeaning]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata_df is mimic-cxr-2.0.0-metadata.csv from https://physionet.org/content/mimic-cxr-jpg/2.0.0/\n",
    "metadata_df = pd.read_csv('mimic-cxr-2.0.0-metadata.csv')\n",
    "metadata_df[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>edregtime</th>\n",
       "      <th>edouttime</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subject_id, hadm_id, admittime, dischtime, deathtime, admission_type, admission_location, discharge_location, insurance, language, marital_status, ethnicity, edregtime, edouttime, hospital_expire_flag]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demographic_df is the addmissions.csv from the \"core\" directory found at https://physionet.org/content/mimiciv/1.0/\n",
    "demographic_df = pd.read_csv('admissions.csv')\n",
    "demographic_df = demographic_df.drop_duplicates(subset='subject_id')\n",
    "demographic_df[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 377110\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images: \" + str(len(metadata_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 65379\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of patients: \" + str(metadata_df.subject_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                            159471\n",
       "BLACK/AFRICAN AMERICAN            31190\n",
       "ASIAN                             16526\n",
       "UNKNOWN                           16464\n",
       "OTHER                             15859\n",
       "HISPANIC/LATINO                   13334\n",
       "UNABLE TO OBTAIN                   3086\n",
       "AMERICAN INDIAN/ALASKA NATIVE       948\n",
       "Name: ethnicity, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_df.ethnicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OTHER_WHITE                                                   2489\n",
       "UNKNOWN_WHITE                                                 1131\n",
       "BLACK/AFRICAN AMERICAN_OTHER                                   560\n",
       "UNABLE TO OBTAIN_WHITE                                         308\n",
       "HISPANIC/LATINO_OTHER                                          307\n",
       "HISPANIC/LATINO_WHITE                                          204\n",
       "HISPANIC/LATINO_UNKNOWN                                        173\n",
       "BLACK/AFRICAN AMERICAN_WHITE                                   168\n",
       "BLACK/AFRICAN AMERICAN_UNKNOWN                                 156\n",
       "OTHER_UNKNOWN                                                  130\n",
       "BLACK/AFRICAN AMERICAN_HISPANIC/LATINO                         111\n",
       "ASIAN_OTHER                                                     98\n",
       "UNABLE TO OBTAIN_UNKNOWN                                        49\n",
       "ASIAN_WHITE                                                     46\n",
       "BLACK/AFRICAN AMERICAN_UNABLE TO OBTAIN                         44\n",
       "ASIAN_UNKNOWN                                                   41\n",
       "OTHER_UNABLE TO OBTAIN                                          29\n",
       "AMERICAN INDIAN/ALASKA NATIVE_WHITE                             28\n",
       "OTHER_UNKNOWN_WHITE                                             21\n",
       "HISPANIC/LATINO_UNABLE TO OBTAIN                                21\n",
       "AMERICAN INDIAN/ALASKA NATIVE_OTHER                             19\n",
       "OTHER_UNABLE TO OBTAIN_WHITE                                    19\n",
       "HISPANIC/LATINO_OTHER_WHITE                                     19\n",
       "ASIAN_UNABLE TO OBTAIN                                          18\n",
       "HISPANIC/LATINO_OTHER_UNKNOWN                                   16\n",
       "BLACK/AFRICAN AMERICAN_OTHER_WHITE                              11\n",
       "AMERICAN INDIAN/ALASKA NATIVE_BLACK/AFRICAN AMERICAN            11\n",
       "ASIAN_BLACK/AFRICAN AMERICAN                                    11\n",
       "UNABLE TO OBTAIN_UNKNOWN_WHITE                                   9\n",
       "HISPANIC/LATINO_UNKNOWN_WHITE                                    8\n",
       "AMERICAN INDIAN/ALASKA NATIVE_UNABLE TO OBTAIN                   8\n",
       "BLACK/AFRICAN AMERICAN_HISPANIC/LATINO_OTHER                     8\n",
       "ASIAN_HISPANIC/LATINO                                            7\n",
       "AMERICAN INDIAN/ALASKA NATIVE_HISPANIC/LATINO                    6\n",
       "AMERICAN INDIAN/ALASKA NATIVE_UNKNOWN                            5\n",
       "AMERICAN INDIAN/ALASKA NATIVE_ASIAN                              4\n",
       "BLACK/AFRICAN AMERICAN_OTHER_UNKNOWN                             4\n",
       "AMERICAN INDIAN/ALASKA NATIVE_BLACK/AFRICAN AMERICAN_OTHER       4\n",
       "ASIAN_UNABLE TO OBTAIN_UNKNOWN                                   3\n",
       "HISPANIC/LATINO_UNABLE TO OBTAIN_UNKNOWN                         3\n",
       "ASIAN_UNKNOWN_WHITE                                              3\n",
       "AMERICAN INDIAN/ALASKA NATIVE_OTHER_WHITE                        2\n",
       "BLACK/AFRICAN AMERICAN_HISPANIC/LATINO_WHITE                     2\n",
       "BLACK/AFRICAN AMERICAN_UNKNOWN_WHITE                             2\n",
       "BLACK/AFRICAN AMERICAN_UNABLE TO OBTAIN_UNKNOWN                  2\n",
       "ASIAN_BLACK/AFRICAN AMERICAN_WHITE                               1\n",
       "BLACK/AFRICAN AMERICAN_HISPANIC/LATINO_OTHER_WHITE               1\n",
       "ASIAN_HISPANIC/LATINO_OTHER                                      1\n",
       "AMERICAN INDIAN/ALASKA NATIVE_ASIAN_OTHER_WHITE                  1\n",
       "AMERICAN INDIAN/ALASKA NATIVE_UNKNOWN_WHITE                      1\n",
       "ASIAN_BLACK/AFRICAN AMERICAN_HISPANIC/LATINO_OTHER               1\n",
       "ASIAN_BLACK/AFRICAN AMERICAN_OTHER                               1\n",
       "BLACK/AFRICAN AMERICAN_OTHER_UNABLE TO OBTAIN                    1\n",
       "BLACK/AFRICAN AMERICAN_HISPANIC/LATINO_OTHER_UNKNOWN             1\n",
       "ASIAN_BLACK/AFRICAN AMERICAN_UNKNOWN                             1\n",
       "BLACK/AFRICAN AMERICAN_OTHER_UNKNOWN_WHITE                       1\n",
       "ASIAN_OTHER_UNKNOWN                                              1\n",
       "ASIAN_OTHER_WHITE                                                1\n",
       "OTHER_UNABLE TO OBTAIN_UNKNOWN_WHITE                             1\n",
       "ASIAN_HISPANIC/LATINO_WHITE                                      1\n",
       "Name: ethnicity, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove patients who have inconsistent documented race information\n",
    "# credit to github.com/robintibor\n",
    "ethnicity_df = demographic_df.loc[:,['subject_id', 'ethnicity']].drop_duplicates()\n",
    "\n",
    "v = ethnicity_df.subject_id.value_counts()\n",
    "subject_id_more_than_once = v.index[v.gt(1)]\n",
    "\n",
    "ambiguous_ethnicity_df = ethnicity_df[ethnicity_df.subject_id.isin(subject_id_more_than_once)]\n",
    "inconsistent_race = ambiguous_ethnicity_df.subject_id.unique()\n",
    "\n",
    "grouped = ambiguous_ethnicity_df.groupby('subject_id')\n",
    "grouped.aggregate(lambda x: \"_\".join(sorted(x))).ethnicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(metadata_df,demographic_df,on='subject_id')\n",
    "merge_df = merge_df[~merge_df.subject_id.isin(inconsistent_race)]\n",
    "merge_df = merge_df.rename(columns={\"ethnicity\": \"race\"})\n",
    "merge_df = merge_df[merge_df.race.isin(['ASIAN','BLACK/AFRICAN AMERICAN','WHITE'])]\n",
    "merge_df = merge_df[merge_df.ViewPosition.isin(['AP','PA'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images after inclusion/exclusion criteria: 183217\n"
     ]
    }
   ],
   "source": [
    "print(\"Total images after inclusion/exclusion criteria: \" + str(len(merge_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patients after inclusion/exclusion criteria: 43209\n"
     ]
    }
   ],
   "source": [
    "print(\"Total patients after inclusion/exclusion criteria: \" + str(merge_df.subject_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = merge_df\n",
    "data_df.insert(5, \"split\",\"none\", True)\n",
    "unique_sub_id = data_df.subject_id.unique()\n",
    "\n",
    "train_percent, valid_percent, test_percent = 0.60, 0.10, 0.30\n",
    "\n",
    "unique_sub_id = shuffle(unique_sub_id)\n",
    "value1 = (round(len(unique_sub_id)*train_percent))\n",
    "value2 = (round(len(unique_sub_id)*valid_percent))\n",
    "value3 = value1 + value2\n",
    "value4 = (round(len(unique_sub_id)*test_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients in training set: 25925\n"
     ]
    }
   ],
   "source": [
    "print(\"Patients in training set: \" + str(value1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients in validation set: 4321\n"
     ]
    }
   ],
   "source": [
    "print(\"Patients in validation set: \" + str(value2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients in testing set: 12963\n"
     ]
    }
   ],
   "source": [
    "print(\"Patients in testing set: \" + str(value4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = shuffle(data_df)\n",
    "\n",
    "train_sub_id = unique_sub_id[:value1]\n",
    "validate_sub_id = unique_sub_id[value1:value3]\n",
    "test_sub_id = unique_sub_id[value3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df.subject_id.isin(train_sub_id), \"split\"]=\"train\"\n",
    "data_df.loc[data_df.subject_id.isin(validate_sub_id), \"split\"]=\"validate\"\n",
    "data_df.loc[data_df.subject_id.isin(test_sub_id), \"split\"]=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train       0.601314\n",
       "test        0.298215\n",
       "validate    0.100471\n",
       "Name: split, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.split.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                     141873\n",
       "BLACK/AFRICAN AMERICAN     34238\n",
       "ASIAN                       7106\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                     0.774344\n",
       "BLACK/AFRICAN AMERICAN    0.186871\n",
       "ASIAN                     0.038785\n",
       "Name: race, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.race.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.subject_id = data_df.subject_id.astype(str)\n",
    "data_df.study_id = data_df.study_id.astype(str)\n",
    "data_df = data_df.fillna(0)\n",
    "data_df.insert(2, \"path\", \"\")\n",
    "data_df.path = data_df.subject_id.str[0:2]\n",
    "data_df.path = \"p\" + data_df.path\n",
    "data_df.path = data_df.path + \"/p\" + data_df.subject_id + \"/s\" + data_df.study_id + \"/\" + data_df.dicom_id + \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('MIMIC_3-race_60-10-30_split_ver_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_df[data_df.split==\"train\"]\n",
    "validation_df = data_df[data_df.split==\"validate\"]\n",
    "test_df = data_df[data_df.split==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False indicates no patient_id shared between groups\n",
    "\n",
    "unique_train_id = train_df.subject_id.unique()\n",
    "unique_validation_id = validation_df.subject_id.unique()\n",
    "unique_test_id = test_df.subject_id.unique()\n",
    "all_id = np.concatenate((unique_train_id, unique_validation_id, unique_test_id), axis=None)\n",
    "\n",
    "def contains_duplicates(X):\n",
    "    return len(np.unique(X)) != len(X)\n",
    "\n",
    "contains_duplicates(all_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 320, 320\n",
    "\n",
    "arc_name = \"MIMIC-\" + str(HEIGHT) + \"x\" + str(WIDTH) + \"_60-10-30-split-resnet-Float16_3-race_detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34, preprocess_input = Classifiers.get('resnet34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "base_model = resnet34(input_tensor=input_a, include_top=False, input_shape=(HEIGHT,WIDTH,3), weights='imagenet')\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(3, name='dense_logits')(x)\n",
    "output = Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "model = Model(inputs=[input_a], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "momentum_val=0.9\n",
    "decay_val= 0.0\n",
    "batch_s = 256 # may need to reduce batch size if OOM error occurs\n",
    "train_batch_size = batch_s\n",
    "test_batch_size = 256\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=2, min_lr=1e-5, verbose=1)\n",
    "\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=learning_rate, decay=decay_val)\n",
    "adam_opt = tf.keras.mixed_precision.LossScaleOptimizer(adam_opt)\n",
    "\n",
    "model.compile(optimizer=adam_opt,\n",
    "                loss=tf.losses.CategoricalCrossentropy(),\n",
    "                metrics=[\n",
    "                    tf.keras.metrics.AUC(curve='ROC', name='ROC-AUC'),\n",
    "                    tf.keras.metrics.AUC(curve='PR', name='PR-AUC')\n",
    "                ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            fill_mode='constant',\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.1,\n",
    "            preprocessing_function=preprocess_input\n",
    "            )\n",
    "\n",
    "validate_gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 110171 validated image filenames belonging to 3 classes.\n",
      "Found 18408 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_gen.flow_from_dataframe(train_df, directory=\"/path/to/directory/\", x_col=\"path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=True,seed=2021,batch_size=train_batch_size, dtype='float32')\n",
    "validate_batches = validate_gen.flow_from_dataframe(validation_df, directory=\"/path/to/directory/\", x_col=\"path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = math.ceil(len(train_df) / train_batch_size)\n",
    "val_epoch = math.ceil(len(validation_df) / test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_date = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "ES = EarlyStopping(monitor='val_loss', mode='min', patience=4, restore_best_weights=True)\n",
    "checkloss = ModelCheckpoint(\"../saved_models/racial_bias/trials/\" + str(arc_name) + \"_CXR_LR-\" + str(learning_rate) + \"_\" + var_date+\"_epoch_{epoch:03d}_val_loss_{val_loss:.5f}.hdf5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 108 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 108 all-reduces with algorithm = nccl, num_packs = 1\n",
      "431/431 [==============================] - 880s 2s/step - loss: 0.5086 - ROC-AUC: 0.9290 - PR-AUC: 0.8746 - val_loss: 0.6313 - val_ROC-AUC: 0.9353 - val_PR-AUC: 0.8921\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63132, saving model to ../saved_models/racial_bias/trials/MIMIC-320x320_60-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210921-190152_epoch_001_val_loss_0.63132.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "431/431 [==============================] - 623s 1s/step - loss: 0.3337 - ROC-AUC: 0.9690 - PR-AUC: 0.9455 - val_loss: 0.7818 - val_ROC-AUC: 0.8585 - val_PR-AUC: 0.7487\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.63132\n",
      "Epoch 3/100\n",
      "431/431 [==============================] - 671s 1s/step - loss: 0.2824 - ROC-AUC: 0.9774 - PR-AUC: 0.9599 - val_loss: 0.4662 - val_ROC-AUC: 0.9437 - val_PR-AUC: 0.8988\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63132 to 0.46624, saving model to ../saved_models/racial_bias/trials/MIMIC-320x320_60-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210921-190152_epoch_003_val_loss_0.46624.hdf5\n",
      "Epoch 4/100\n",
      "431/431 [==============================] - 635s 1s/step - loss: 0.2501 - ROC-AUC: 0.9819 - PR-AUC: 0.9675 - val_loss: 0.4150 - val_ROC-AUC: 0.9530 - val_PR-AUC: 0.9141\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46624 to 0.41500, saving model to ../saved_models/racial_bias/trials/MIMIC-320x320_60-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210921-190152_epoch_004_val_loss_0.41500.hdf5\n",
      "Epoch 5/100\n",
      "431/431 [==============================] - 605s 1s/step - loss: 0.2275 - ROC-AUC: 0.9848 - PR-AUC: 0.9726 - val_loss: 0.3189 - val_ROC-AUC: 0.9713 - val_PR-AUC: 0.9479\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41500 to 0.31885, saving model to ../saved_models/racial_bias/trials/MIMIC-320x320_60-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210921-190152_epoch_005_val_loss_0.31885.hdf5\n",
      "Epoch 6/100\n",
      "431/431 [==============================] - 610s 1s/step - loss: 0.2111 - ROC-AUC: 0.9868 - PR-AUC: 0.9760 - val_loss: 0.3279 - val_ROC-AUC: 0.9740 - val_PR-AUC: 0.9535\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31885\n",
      "Epoch 7/100\n",
      "431/431 [==============================] - 614s 1s/step - loss: 0.1987 - ROC-AUC: 0.9881 - PR-AUC: 0.9782 - val_loss: 0.2391 - val_ROC-AUC: 0.9835 - val_PR-AUC: 0.9699\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.31885 to 0.23913, saving model to ../saved_models/racial_bias/trials/MIMIC-320x320_60-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210921-190152_epoch_007_val_loss_0.23913.hdf5\n",
      "Epoch 8/100\n",
      "431/431 [==============================] - 608s 1s/step - loss: 0.1866 - ROC-AUC: 0.9894 - PR-AUC: 0.9807 - val_loss: 0.2976 - val_ROC-AUC: 0.9793 - val_PR-AUC: 0.9615\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23913\n",
      "Epoch 9/100\n",
      "431/431 [==============================] - 630s 1s/step - loss: 0.1780 - ROC-AUC: 0.9902 - PR-AUC: 0.9821 - val_loss: 0.3979 - val_ROC-AUC: 0.9594 - val_PR-AUC: 0.9247\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23913\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/100\n",
      "431/431 [==============================] - 585s 1s/step - loss: 0.1366 - ROC-AUC: 0.9939 - PR-AUC: 0.9887 - val_loss: 0.1815 - val_ROC-AUC: 0.9890 - val_PR-AUC: 0.9798\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.23913 to 0.18153, saving model to ../saved_models/racial_bias/trials/MIMIC-320x320_60-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210921-190152_epoch_010_val_loss_0.18153.hdf5\n",
      "Epoch 11/100\n",
      "431/431 [==============================] - 609s 1s/step - loss: 0.1229 - ROC-AUC: 0.9948 - PR-AUC: 0.9904 - val_loss: 0.2042 - val_ROC-AUC: 0.9873 - val_PR-AUC: 0.9764\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18153\n",
      "Epoch 12/100\n",
      "431/431 [==============================] - 601s 1s/step - loss: 0.1161 - ROC-AUC: 0.9954 - PR-AUC: 0.9913 - val_loss: 0.1746 - val_ROC-AUC: 0.9897 - val_PR-AUC: 0.9811\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18153 to 0.17461, saving model to ../saved_models/racial_bias/trials/MIMIC-320x320_60-10-30-split-resnet-Float16_3-race_detection_CXR_LR-0.001_20210921-190152_epoch_012_val_loss_0.17461.hdf5\n",
      "Epoch 13/100\n",
      "431/431 [==============================] - 604s 1s/step - loss: 0.1111 - ROC-AUC: 0.9956 - PR-AUC: 0.9918 - val_loss: 0.1897 - val_ROC-AUC: 0.9886 - val_PR-AUC: 0.9790\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.17461\n",
      "Epoch 14/100\n",
      "431/431 [==============================] - 614s 1s/step - loss: 0.1085 - ROC-AUC: 0.9958 - PR-AUC: 0.9922 - val_loss: 0.1769 - val_ROC-AUC: 0.9896 - val_PR-AUC: 0.9808\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17461\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 15/100\n",
      "431/431 [==============================] - 603s 1s/step - loss: 0.1012 - ROC-AUC: 0.9963 - PR-AUC: 0.9931 - val_loss: 0.1764 - val_ROC-AUC: 0.9897 - val_PR-AUC: 0.9812\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.17461\n",
      "Epoch 16/100\n",
      "431/431 [==============================] - 608s 1s/step - loss: 0.0991 - ROC-AUC: 0.9963 - PR-AUC: 0.9931 - val_loss: 0.1799 - val_ROC-AUC: 0.9894 - val_PR-AUC: 0.9805\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.17461\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa9aa3627b8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_batches,\n",
    "            validation_data=validate_batches,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=int(train_epoch),\n",
    "            validation_steps=int(val_epoch),\n",
    "            workers=32,\n",
    "            max_queue_size=50,\n",
    "            shuffle=True,\n",
    "            callbacks=[checkloss, reduce_lr, ES]\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                     0.776749\n",
       "BLACK/AFRICAN AMERICAN    0.184231\n",
       "ASIAN                     0.039020\n",
       "Name: race, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.race.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54638 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = validate_gen.flow_from_dataframe(test_df, directory=\"/path/to/directory/\", x_col=\"path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 404s 2s/step\n"
     ]
    }
   ],
   "source": [
    "multilabel_predict_test = model.predict(test_batches, max_queue_size=10, verbose=1, steps=math.ceil(len(test_df)/test_batch_size), workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prediction = multilabel_predict_test\n",
    "input_df = test_df\n",
    "input_prediction_df = pd.DataFrame(input_prediction)\n",
    "true_logits = pd.DataFrame()\n",
    "loss_log = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_calc(input_prediction_df, input_df):\n",
    "    ground_truth = input_df.race\n",
    "    pathology_array=[\n",
    "        'ASIAN',\n",
    "        'BLACK/AFRICAN AMERICAN',\n",
    "        'WHITE'\n",
    "        ]\n",
    "    i=0\n",
    "    auc_array = []\n",
    "    for pathology in pathology_array:\n",
    "    \n",
    "        new_truth = (ground_truth.str.contains(pathology)).apply(int)\n",
    "        input_prediction_val = input_prediction_df[i]\n",
    "        val = input_prediction_val\n",
    "        AUC = roc_auc_score(new_truth, val)\n",
    "        true_logits.insert(i, i, new_truth, True)\n",
    "        auc_array.append(AUC)\n",
    "        i += 1\n",
    "        \n",
    "    progress_df = pd.DataFrame({'Study':pathology_array, 'AUC':auc_array})\n",
    "    print(progress_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Study       AUC\n",
      "0                   ASIAN  0.972251\n",
      "1  BLACK/AFRICAN AMERICAN  0.982361\n",
      "2                   WHITE  0.976957\n"
     ]
    }
   ],
   "source": [
    "stat_calc(input_prediction_df, input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classwise ROC AUC \n",
      "\n",
      "Class - Asian ROC-AUC- 0.97\n",
      "Class - Black ROC-AUC- 0.98\n",
      "Class - White ROC-AUC- 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Asian       0.87      0.68      0.76      2132\n",
      "       Black       0.94      0.84      0.88     10066\n",
      "       White       0.95      0.99      0.97     42440\n",
      "\n",
      "    accuracy                           0.95     54638\n",
      "   macro avg       0.92      0.83      0.87     54638\n",
      "weighted avg       0.95      0.95      0.94     54638\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = multilabel_predict_test\n",
    "#result = model.predict(validate_batches, val_epoch)\n",
    "labels = np.argmax(result, axis=1)\n",
    "target_names = ['Asian', 'Black', 'White']\n",
    "\n",
    "print ('Classwise ROC AUC \\n')\n",
    "for p in list(set(labels)):\n",
    "    fpr, tpr, thresholds = roc_curve(test_batches.classes, result[:,p], pos_label = p)\n",
    "    auroc = round(auc(fpr, tpr), 2)\n",
    "    print ('Class - {} ROC-AUC- {}'.format(target_names[p], auroc))\n",
    "\n",
    "print (classification_report(test_batches.classes, labels, target_names=target_names))\n",
    "class_matrix = confusion_matrix(test_batches.classes, labels)\n",
    "\n",
    "sns.heatmap(class_matrix, annot=True, fmt='d', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
