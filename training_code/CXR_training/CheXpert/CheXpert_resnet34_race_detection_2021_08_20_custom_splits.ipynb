{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model was made using a docker image\n",
    "# Docker image can be found at https://hub.docker.com/r/blackboxradiology/tf-2.6_with_pytorch\n",
    "# docker pull blackboxradiology/tf-2.6_with_pytorch\n",
    "\n",
    "# python version 3.6.9\n",
    "# mayplotlib version 3.3.4\n",
    "# numpy version 1.19.5\n",
    "# pandas version 1.1.5\n",
    "# PIL version 8.2.0\n",
    "# sklearn version 0.24.2\n",
    "# tensorflow version 2.6.0\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random as python_random\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Dense, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "# pip install image-classifiers==1.0.0b1\n",
    "from classification_models.tfkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "python_random.seed(2021)\n",
    "tf.random.set_seed(2021)\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(mirrored_strategy.num_replicas_in_sync))\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = pd.DataFrame(pd.read_excel(\"CHEXPERT DEMO.xlsx\", engine='openpyxl')) #pip install openpyxl\n",
    "data_df = pd.read_csv('chexpert_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE_AT_CXR</th>\n",
       "      <th>PRIMARY_RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PATIENT, GENDER, AGE_AT_CXR, PRIMARY_RACE, ETHNICITY]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>FrontalLateral</th>\n",
       "      <th>Position</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Path, Sex, Age, FrontalLateral, Position, No Finding, Enlarged Cardiomediastinum, Cardiomegaly, Lung Opacity, Lung Lesion, Edema, Consolidation, Pneumonia, Atelectasis, Pneumothorax, Pleural Effusion, Pleural Other, Fracture, Support Devices]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 223414\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images: \" + str(len(data_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 65401\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of patients: \" + str(len(demo_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split =  data_df.Path.str.split(\"/\", expand = True)\n",
    "data_df[\"patient_id\"] = split[2]\n",
    "demo_df = demo_df.rename(columns={'PATIENT': 'patient_id'})\n",
    "combine_df = data_df.merge(demo_df, on=\"patient_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White                                        102402\n",
       "Other                                         28095\n",
       "White, non-Hispanic                           22154\n",
       "Asian                                         20434\n",
       "Unknown                                       15186\n",
       "Black or African American                      9909\n",
       "Race and Ethnicity Unknown                     8716\n",
       "Other, Hispanic                                3621\n",
       "Native Hawaiian or Other Pacific Islander      2809\n",
       "Asian, non-Hispanic                            2793\n",
       "Black, non-Hispanic                            2000\n",
       "White, Hispanic                                 922\n",
       "Other, non-Hispanic                             566\n",
       "American Indian or Alaska Native                457\n",
       "Patient Refused                                 405\n",
       "Pacific Islander, non-Hispanic                  337\n",
       "Native American, non-Hispanic                    55\n",
       "Black, Hispanic                                  52\n",
       "Asian, Hispanic                                  37\n",
       "Native American, Hispanic                        25\n",
       "White or Caucasian                               13\n",
       "Pacific Islander, Hispanic                       10\n",
       "Asian - Historical Conv                           8\n",
       "Name: PRIMARY_RACE, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.PRIMARY_RACE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df.insert(3, \"race\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (combine_df.PRIMARY_RACE.str.contains(\"Black\", na=False))\n",
    "combine_df.loc[mask, \"race\"] = \"BLACK/AFRICAN AMERICAN\"\n",
    "\n",
    "mask = (combine_df.PRIMARY_RACE.str.contains(\"White\", na=False))\n",
    "combine_df.loc[mask, \"race\"] = \"WHITE\"\n",
    "\n",
    "mask = (combine_df.PRIMARY_RACE.str.contains(\"Asian\", na=False))\n",
    "combine_df.loc[mask, \"race\"] = \"ASIAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all labels that are not asian, black or white\n",
    "combine_df = combine_df[combine_df.race.isin(['ASIAN','BLACK/AFRICAN AMERICAN','WHITE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-Hispanic/Non-Latino    149268\n",
       "Unknown                      6546\n",
       "Hispanic/Latino              4726\n",
       "Patient Refused               160\n",
       "Not Hispanic                   15\n",
       "Hispanic                        1\n",
       "Name: ETHNICITY, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.ETHNICITY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only non-hispanic labels\n",
    "combine_df = combine_df[combine_df.ETHNICITY.isin([\"Non-Hispanic/Non-Latino\",\"Not Hispanic\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frontal images only (AP/PA)\n",
    "combine_df = combine_df[combine_df[\"FrontalLateral\"]==\"Frontal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images after inclusion/exclusion criteria: 127130\n"
     ]
    }
   ],
   "source": [
    "print(\"Total images after inclusion/exclusion criteria: \" + str(len(combine_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patients after inclusion/exclusion criteria: 64540\n"
     ]
    }
   ],
   "source": [
    "print(\"Total patients after inclusion/exclusion criteria: \" + str(combine_df.patient_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = combine_df\n",
    "data_df.insert(5, \"split\",\"none\", True)\n",
    "unique_sub_id = data_df.patient_id.unique()\n",
    "\n",
    "train_percent, valid_percent, test_percent = 0.60, 0.10, 0.30\n",
    "\n",
    "unique_sub_id = shuffle(unique_sub_id)\n",
    "value1 = (round(len(unique_sub_id)*train_percent))\n",
    "value2 = (round(len(unique_sub_id)*valid_percent))\n",
    "value3 = value1 + value2\n",
    "value4 = (round(len(unique_sub_id)*test_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients in training set: 25730\n"
     ]
    }
   ],
   "source": [
    "print(\"Patients in training set: \" + str(value1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients in validation set: 4288\n"
     ]
    }
   ],
   "source": [
    "print(\"Patients in validation set: \" + str(value2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients in testing set: 12865\n"
     ]
    }
   ],
   "source": [
    "print(\"Patients in testing set: \" + str(value4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = shuffle(data_df)\n",
    "\n",
    "train_sub_id = unique_sub_id[:value1]\n",
    "validate_sub_id = unique_sub_id[value1:value3]\n",
    "test_sub_id = unique_sub_id[value3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df.patient_id.isin(train_sub_id), \"split\"]=\"train\"\n",
    "data_df.loc[data_df.patient_id.isin(validate_sub_id), \"split\"]=\"validate\"\n",
    "data_df.loc[data_df.patient_id.isin(test_sub_id), \"split\"]=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train       0.599481\n",
       "test        0.300818\n",
       "validate    0.099701\n",
       "Name: split, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.split.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                     99037\n",
       "ASIAN                     18830\n",
       "BLACK/AFRICAN AMERICAN     9263\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE                     0.779021\n",
       "ASIAN                     0.148116\n",
       "BLACK/AFRICAN AMERICAN    0.072862\n",
       "Name: race, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.race.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up\n",
    "data_df = data_df.sort_values(by=['Path'])\n",
    "data_df = data_df.reset_index()\n",
    "data_df = data_df.drop(columns=['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[data_df.Position.isin(['AP','PA'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_df[data_df.split==\"train\"]\n",
    "validation_df = data_df[data_df.split==\"validate\"]\n",
    "test_df = data_df[data_df.split==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False indicates no patient_id shared between groups\n",
    "\n",
    "unique_train_id = train_df.patient_id.unique()\n",
    "unique_validation_id = validation_df.patient_id.unique()\n",
    "unique_test_id = test_df.patient_id.unique()\n",
    "all_id = np.concatenate((unique_train_id, unique_validation_id, unique_test_id), axis=None)\n",
    "\n",
    "def contains_duplicates(X):\n",
    "    return len(np.unique(X)) != len(X)\n",
    "\n",
    "contains_duplicates(all_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 320, 320\n",
    "\n",
    "arc_name = \"CHEXPERT-\" + str(HEIGHT) + \"x\" + str(WIDTH) + \"_60-10-30-split-resnet34-Float16_3-race_detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34, preprocess_input = Classifiers.get('resnet34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    input_a = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    base_model = resnet34(input_tensor=input_a, include_top=False, input_shape=(HEIGHT,WIDTH,3), weights='imagenet')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(3, name='dense_logits')(x)\n",
    "    output = Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "    model = Model(inputs=[input_a], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "momentum_val=0.9\n",
    "decay_val= 0.0\n",
    "train_batch_size = 256 # may need to reduce batch size if OOM error occurs\n",
    "test_batch_size = 256\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=2, min_lr=1e-5, verbose=1)\n",
    "\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=learning_rate, decay=decay_val)\n",
    "adam_opt = tf.keras.mixed_precision.LossScaleOptimizer(adam_opt)\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    model.compile(optimizer=adam_opt,\n",
    "                    loss=tf.losses.CategoricalCrossentropy(),\n",
    "                    metrics=[\n",
    "                        tf.keras.metrics.AUC(curve='ROC', name='ROC-AUC'),\n",
    "                        tf.keras.metrics.AUC(curve='PR', name='PR-AUC')\n",
    "                    ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            fill_mode='constant',\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.1,\n",
    "            preprocessing_function=preprocess_input\n",
    "            )\n",
    "\n",
    "validate_gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76205 validated image filenames belonging to 3 classes.\n",
      "Found 12673 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_gen.flow_from_dataframe(train_df, directory=\"/tf/notebooks/SSD_data/chexpert_directory/\", x_col=\"Path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=True,seed=2021,batch_size=train_batch_size, dtype='float32')\n",
    "validate_batches = validate_gen.flow_from_dataframe(validation_df, directory=\"/tf/notebooks/SSD_data/chexpert_directory/\", x_col=\"Path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = math.ceil(len(train_df) / train_batch_size)\n",
    "val_epoch = math.ceil(len(validation_df) / test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_date = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "ES = EarlyStopping(monitor='val_loss', mode='min', patience=4, restore_best_weights=True)\n",
    "checkloss = ModelCheckpoint(\"../saved_models/racial_bias/trials/\" + str(arc_name) + \"_CXR_LR-\" + str(learning_rate) + \"_\" + var_date+\"_epoch:{epoch:03d}_val_loss:{val_loss:.5f}.hdf5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 108 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 108 all-reduces with algorithm = nccl, num_packs = 1\n",
      "298/298 [==============================] - 551s 2s/step - loss: 0.4800 - ROC-AUC: 0.9374 - PR-AUC: 0.8913 - val_loss: 0.8220 - val_ROC-AUC: 0.9188 - val_PR-AUC: 0.8732\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.82205, saving model to ../saved_models/racial_bias/trials/CHEXPERT-320x320_60-10-30-split-resnet34-Float16_3-race_detection_CXR_LR-0.001_20210818-211230_epoch:001_val_loss:0.82205.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "298/298 [==============================] - 492s 2s/step - loss: 0.3307 - ROC-AUC: 0.9695 - PR-AUC: 0.9454 - val_loss: 0.4644 - val_ROC-AUC: 0.9483 - val_PR-AUC: 0.9092\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.82205 to 0.46438, saving model to ../saved_models/racial_bias/trials/CHEXPERT-320x320_60-10-30-split-resnet34-Float16_3-race_detection_CXR_LR-0.001_20210818-211230_epoch:002_val_loss:0.46438.hdf5\n",
      "Epoch 3/100\n",
      "298/298 [==============================] - 494s 2s/step - loss: 0.2830 - ROC-AUC: 0.9772 - PR-AUC: 0.9589 - val_loss: 0.4079 - val_ROC-AUC: 0.9624 - val_PR-AUC: 0.9354\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46438 to 0.40790, saving model to ../saved_models/racial_bias/trials/CHEXPERT-320x320_60-10-30-split-resnet34-Float16_3-race_detection_CXR_LR-0.001_20210818-211230_epoch:003_val_loss:0.40790.hdf5\n",
      "Epoch 4/100\n",
      "298/298 [==============================] - 495s 2s/step - loss: 0.2545 - ROC-AUC: 0.9812 - PR-AUC: 0.9656 - val_loss: 0.3118 - val_ROC-AUC: 0.9755 - val_PR-AUC: 0.9562\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.40790 to 0.31179, saving model to ../saved_models/racial_bias/trials/CHEXPERT-320x320_60-10-30-split-resnet34-Float16_3-race_detection_CXR_LR-0.001_20210818-211230_epoch:004_val_loss:0.31179.hdf5\n",
      "Epoch 5/100\n",
      "298/298 [==============================] - 497s 2s/step - loss: 0.2407 - ROC-AUC: 0.9829 - PR-AUC: 0.9685 - val_loss: 0.3397 - val_ROC-AUC: 0.9752 - val_PR-AUC: 0.9542\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.31179\n",
      "Epoch 6/100\n",
      "298/298 [==============================] - 496s 2s/step - loss: 0.2257 - ROC-AUC: 0.9849 - PR-AUC: 0.9723 - val_loss: 0.4189 - val_ROC-AUC: 0.9600 - val_PR-AUC: 0.9311\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.31179\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/100\n",
      "298/298 [==============================] - 497s 2s/step - loss: 0.1763 - ROC-AUC: 0.9901 - PR-AUC: 0.9813 - val_loss: 0.2191 - val_ROC-AUC: 0.9852 - val_PR-AUC: 0.9735\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.31179 to 0.21913, saving model to ../saved_models/racial_bias/trials/CHEXPERT-320x320_60-10-30-split-resnet34-Float16_3-race_detection_CXR_LR-0.001_20210818-211230_epoch:007_val_loss:0.21913.hdf5\n",
      "Epoch 8/100\n",
      "298/298 [==============================] - 496s 2s/step - loss: 0.1589 - ROC-AUC: 0.9918 - PR-AUC: 0.9846 - val_loss: 0.2221 - val_ROC-AUC: 0.9852 - val_PR-AUC: 0.9732\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21913\n",
      "Epoch 9/100\n",
      "298/298 [==============================] - 496s 2s/step - loss: 0.1507 - ROC-AUC: 0.9924 - PR-AUC: 0.9855 - val_loss: 0.2251 - val_ROC-AUC: 0.9849 - val_PR-AUC: 0.9717\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.21913\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/100\n",
      "298/298 [==============================] - 496s 2s/step - loss: 0.1411 - ROC-AUC: 0.9933 - PR-AUC: 0.9872 - val_loss: 0.2234 - val_ROC-AUC: 0.9853 - val_PR-AUC: 0.9730\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.21913\n",
      "Epoch 11/100\n",
      "298/298 [==============================] - 497s 2s/step - loss: 0.1385 - ROC-AUC: 0.9935 - PR-AUC: 0.9879 - val_loss: 0.2250 - val_ROC-AUC: 0.9852 - val_PR-AUC: 0.9728\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.21913\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75904fb9b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_batches,\n",
    "            validation_data=validate_batches,\n",
    "            epochs=100,\n",
    "            steps_per_epoch=int(train_epoch),\n",
    "            validation_steps=int(val_epoch),\n",
    "            workers=32,\n",
    "            max_queue_size=50,\n",
    "            shuffle=False,\n",
    "            callbacks=[checkloss, reduce_lr, ES]\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38240 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = validate_gen.flow_from_dataframe(test_df, directory=\"/tf/notebooks/fishtank/radiology_datasets/CheXpert_Xray_dataset/resize_chexpert_320x320/chexpert_data/\", x_col=\"Path\", y_col=\"race\", class_mode=\"categorical\",target_size=(HEIGHT, WIDTH),shuffle=False,batch_size=test_batch_size, dtype='float32')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 98s 629ms/step\n"
     ]
    }
   ],
   "source": [
    "with mirrored_strategy.scope():\n",
    "\n",
    "    multilabel_predict_test = model.predict(test_batches, max_queue_size=10, verbose=1, steps=math.ceil(len(test_df)/test_batch_size), workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prediction = multilabel_predict_test\n",
    "input_df = test_df\n",
    "input_prediction_df = pd.DataFrame(input_prediction)\n",
    "true_logits = pd.DataFrame()\n",
    "loss_log = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_calc(input_prediction_df, input_df):\n",
    "    ground_truth = input_df.race\n",
    "    pathology_array=[\n",
    "        'ASIAN',\n",
    "        'BLACK/AFRICAN AMERICAN',\n",
    "        'WHITE'\n",
    "        ]\n",
    "    i=0\n",
    "    auc_array = []\n",
    "    for pathology in pathology_array:\n",
    "    \n",
    "        new_truth = (ground_truth.str.contains(pathology)).apply(int)\n",
    "        input_prediction_val = input_prediction_df[i]\n",
    "        val = input_prediction_val\n",
    "        AUC = roc_auc_score(new_truth, val)\n",
    "        true_logits.insert(i, i, new_truth, True)\n",
    "        auc_array.append(AUC)\n",
    "        i += 1\n",
    "        \n",
    "    progress_df = pd.DataFrame({'Study':pathology_array, 'AUC':auc_array})\n",
    "    print(progress_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Study       AUC\n",
      "0                   ASIAN  0.975544\n",
      "1  BLACK/AFRICAN AMERICAN  0.980552\n",
      "2                   WHITE  0.973676\n"
     ]
    }
   ],
   "source": [
    "stat_calc(input_prediction_df, input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "#import h5py\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import auc, accuracy_score, recall_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classwise ROC AUC \n",
      "\n",
      "Class - Asian ROC-AUC- 0.98\n",
      "Class - Black ROC-AUC- 0.98\n",
      "Class - White ROC-AUC- 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Asian       0.87      0.82      0.85      5650\n",
      "       Black       0.89      0.75      0.81      2746\n",
      "       White       0.95      0.97      0.96     29844\n",
      "\n",
      "    accuracy                           0.94     38240\n",
      "   macro avg       0.90      0.85      0.87     38240\n",
      "weighted avg       0.93      0.94      0.93     38240\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = multilabel_predict_test\n",
    "#result = model.predict(validate_batches, val_epoch)\n",
    "labels = np.argmax(result, axis=1)\n",
    "target_names = ['Asian', 'Black', 'White']\n",
    "\n",
    "print ('Classwise ROC AUC \\n')\n",
    "for p in list(set(labels)):\n",
    "    fpr, tpr, thresholds = roc_curve(test_batches.classes, result[:,p], pos_label = p)\n",
    "    auroc = round(auc(fpr, tpr), 2)\n",
    "    print ('Class - {} ROC-AUC- {}'.format(target_names[p], auroc))\n",
    "\n",
    "print (classification_report(test_batches.classes, labels, target_names=target_names))\n",
    "class_matrix = confusion_matrix(test_batches.classes, labels)\n",
    "\n",
    "sns.heatmap(class_matrix, annot=True, fmt='d', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
