{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aab02dd",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8966f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d9f9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5599.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5024.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6114.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6127.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename race gender\n",
       "0  5599.jpg    0      F\n",
       "1  5004.jpg    0      F\n",
       "2  5024.jpg    0      F\n",
       "3  6114.jpg    0      F\n",
       "4  6127.jpg    0      F"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_height = 320\n",
    "img_width = 320\n",
    "batch_size = 8\n",
    "\n",
    "train_data_dir = \"../IMAGES/\"\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "metadata_df = pd.read_csv('../metadata.csv')\n",
    "metadata_df['race'] = pd.Categorical(pd.factorize(metadata_df.race)[0])\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ecce600",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['race'] = metadata_df['race'].replace(0, 'Asian')\n",
    "metadata_df['race'] = metadata_df['race'].replace(1, 'Black')\n",
    "metadata_df['race'] = metadata_df['race'].replace(2, 'Caucasian')\n",
    "metadata_df['race'] = metadata_df['race'].replace(3, 'Hispanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d32a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = metadata_df[(metadata_df['race'] == 'Black') |\n",
    "                          ((metadata_df['race'] == 'Caucasian'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1407b14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Black        358\n",
       "Caucasian    333\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(metadata_df['race'].value_counts().index)\n",
    "metadata_df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0ca5e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Black', 'Caucasian'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "metadata_df['race'] = le.fit_transform(metadata_df['race'])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c0677f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    351\n",
       "F    340\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b25d3d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in metadata_df['filename']:\n",
    "    key  = i\n",
    "    label = metadata_df.loc[metadata_df['filename'] == key].iloc[0]['race']\n",
    "    labels.append(label)\n",
    "    filepath = train_data_dir+i\n",
    "    image=tf.keras.preprocessing.image.load_img(filepath, color_mode='rgb', target_size= (img_height,img_width))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.20, random_state=42) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070528ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "test_data = (X_test, y_test)\n",
    "pickle.dump(test_data, open('../test_data_dha_2_classes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bffef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "X_val = np.asarray(X_val)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "969e0eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X_train[10], interpolation='nearest')\n",
    "plt.show()\n",
    "display(y_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282099e",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5f07180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, concatenate, add, GlobalAveragePooling2D, BatchNormalization, Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from classification_models.tfkeras import Classifiers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "resnet34, preprocess_input = Classifiers.get('resnet50')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "input_a = Input(shape=(img_height, img_width, 3))\n",
    "base_model = resnet34(input_tensor=input_a, include_top=False, input_shape=(img_height, img_width,3), weights='imagenet')\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dense(num_classes, name='dense_logits')(x)\n",
    "output = layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "model = Model(inputs=[input_a], outputs=[output])\n",
    "\n",
    "adam_opt = Adam(lr=0.000001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=2, min_lr=1e-6, verbose=1)\n",
    "model.compile(optimizer=adam_opt, loss=tf.losses.CategoricalCrossentropy(),\n",
    "                    metrics=[\n",
    "                        tf.keras.metrics.AUC(curve='ROC', name='ROC-AUC'),\n",
    "                        tf.keras.metrics.AUC(curve='PR', name='PR-AUC')\n",
    "                    ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2441236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "y_val_cat = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fd580",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2064f60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 483 samples, validate on 69 samples\n",
      "Epoch 1/100\n",
      "483/483 [==============================] - 14s 29ms/sample - loss: 0.7112 - ROC-AUC: 0.5332 - PR-AUC: 0.5126 - val_loss: 0.7675 - val_ROC-AUC: 0.4033 - val_PR-AUC: 0.4225\n",
      "Epoch 2/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.6822 - ROC-AUC: 0.5925 - PR-AUC: 0.5768 - val_loss: 0.7336 - val_ROC-AUC: 0.4500 - val_PR-AUC: 0.4538\n",
      "Epoch 3/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.6647 - ROC-AUC: 0.6375 - PR-AUC: 0.6208 - val_loss: 0.7190 - val_ROC-AUC: 0.4789 - val_PR-AUC: 0.4806\n",
      "Epoch 4/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.6482 - ROC-AUC: 0.6818 - PR-AUC: 0.6656 - val_loss: 0.7075 - val_ROC-AUC: 0.5090 - val_PR-AUC: 0.5002\n",
      "Epoch 5/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.6409 - ROC-AUC: 0.7010 - PR-AUC: 0.6888 - val_loss: 0.7064 - val_ROC-AUC: 0.5177 - val_PR-AUC: 0.4990\n",
      "Epoch 6/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.6116 - ROC-AUC: 0.7758 - PR-AUC: 0.7684 - val_loss: 0.7044 - val_ROC-AUC: 0.5316 - val_PR-AUC: 0.5053\n",
      "Epoch 7/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.5962 - ROC-AUC: 0.8073 - PR-AUC: 0.8045 - val_loss: 0.6984 - val_ROC-AUC: 0.5579 - val_PR-AUC: 0.5230\n",
      "Epoch 8/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.5772 - ROC-AUC: 0.8482 - PR-AUC: 0.8478 - val_loss: 0.6902 - val_ROC-AUC: 0.5880 - val_PR-AUC: 0.5569\n",
      "Epoch 9/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.5672 - ROC-AUC: 0.8657 - PR-AUC: 0.8674 - val_loss: 0.6830 - val_ROC-AUC: 0.6127 - val_PR-AUC: 0.5727\n",
      "Epoch 10/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.5459 - ROC-AUC: 0.9062 - PR-AUC: 0.9045 - val_loss: 0.6742 - val_ROC-AUC: 0.6303 - val_PR-AUC: 0.5874\n",
      "Epoch 11/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.5525 - ROC-AUC: 0.8860 - PR-AUC: 0.8889 - val_loss: 0.6656 - val_ROC-AUC: 0.6455 - val_PR-AUC: 0.6007\n",
      "Epoch 12/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.5306 - ROC-AUC: 0.9221 - PR-AUC: 0.9240 - val_loss: 0.6554 - val_ROC-AUC: 0.6648 - val_PR-AUC: 0.6240\n",
      "Epoch 13/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.5180 - ROC-AUC: 0.9340 - PR-AUC: 0.9316 - val_loss: 0.6454 - val_ROC-AUC: 0.6856 - val_PR-AUC: 0.6522\n",
      "Epoch 14/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.5063 - ROC-AUC: 0.9458 - PR-AUC: 0.9466 - val_loss: 0.6377 - val_ROC-AUC: 0.6993 - val_PR-AUC: 0.6757\n",
      "Epoch 15/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.4904 - ROC-AUC: 0.9576 - PR-AUC: 0.9576 - val_loss: 0.6324 - val_ROC-AUC: 0.7065 - val_PR-AUC: 0.6878\n",
      "Epoch 16/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.4763 - ROC-AUC: 0.9626 - PR-AUC: 0.9637 - val_loss: 0.6264 - val_ROC-AUC: 0.7116 - val_PR-AUC: 0.6964\n",
      "Epoch 17/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.4688 - ROC-AUC: 0.9661 - PR-AUC: 0.9644 - val_loss: 0.6214 - val_ROC-AUC: 0.7203 - val_PR-AUC: 0.7103\n",
      "Epoch 18/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.4521 - ROC-AUC: 0.9760 - PR-AUC: 0.9767 - val_loss: 0.6167 - val_ROC-AUC: 0.7279 - val_PR-AUC: 0.7192\n",
      "Epoch 19/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.4486 - ROC-AUC: 0.9744 - PR-AUC: 0.9746 - val_loss: 0.6121 - val_ROC-AUC: 0.7307 - val_PR-AUC: 0.7197\n",
      "Epoch 20/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.4297 - ROC-AUC: 0.9812 - PR-AUC: 0.9811 - val_loss: 0.6080 - val_ROC-AUC: 0.7322 - val_PR-AUC: 0.7225\n",
      "Epoch 21/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.4244 - ROC-AUC: 0.9816 - PR-AUC: 0.9814 - val_loss: 0.6050 - val_ROC-AUC: 0.7336 - val_PR-AUC: 0.7226\n",
      "Epoch 22/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.4138 - ROC-AUC: 0.9868 - PR-AUC: 0.9870 - val_loss: 0.6029 - val_ROC-AUC: 0.7368 - val_PR-AUC: 0.7271\n",
      "Epoch 23/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.4011 - ROC-AUC: 0.9867 - PR-AUC: 0.9865 - val_loss: 0.5993 - val_ROC-AUC: 0.7446 - val_PR-AUC: 0.7345\n",
      "Epoch 24/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3909 - ROC-AUC: 0.9879 - PR-AUC: 0.9865 - val_loss: 0.5993 - val_ROC-AUC: 0.7379 - val_PR-AUC: 0.7276\n",
      "Epoch 25/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3791 - ROC-AUC: 0.9921 - PR-AUC: 0.9920 - val_loss: 0.5993 - val_ROC-AUC: 0.7398 - val_PR-AUC: 0.7285\n",
      "Epoch 26/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3733 - ROC-AUC: 0.9904 - PR-AUC: 0.9907 - val_loss: 0.5968 - val_ROC-AUC: 0.7447 - val_PR-AUC: 0.7339\n",
      "Epoch 27/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3665 - ROC-AUC: 0.9875 - PR-AUC: 0.9852 - val_loss: 0.5962 - val_ROC-AUC: 0.7442 - val_PR-AUC: 0.7321\n",
      "Epoch 28/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3466 - ROC-AUC: 0.9930 - PR-AUC: 0.9932 - val_loss: 0.5966 - val_ROC-AUC: 0.7438 - val_PR-AUC: 0.7343\n",
      "Epoch 29/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3452 - ROC-AUC: 0.9954 - PR-AUC: 0.9955 - val_loss: 0.5934 - val_ROC-AUC: 0.7481 - val_PR-AUC: 0.7406\n",
      "Epoch 30/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3337 - ROC-AUC: 0.9935 - PR-AUC: 0.9937 - val_loss: 0.5937 - val_ROC-AUC: 0.7504 - val_PR-AUC: 0.7432\n",
      "Epoch 31/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3218 - ROC-AUC: 0.9951 - PR-AUC: 0.9951 - val_loss: 0.5941 - val_ROC-AUC: 0.7472 - val_PR-AUC: 0.7382\n",
      "Epoch 32/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3167 - ROC-AUC: 0.9962 - PR-AUC: 0.9963 - val_loss: 0.5930 - val_ROC-AUC: 0.7477 - val_PR-AUC: 0.7336\n",
      "Epoch 33/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3156 - ROC-AUC: 0.9938 - PR-AUC: 0.9940 - val_loss: 0.5898 - val_ROC-AUC: 0.7511 - val_PR-AUC: 0.7363\n",
      "Epoch 34/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.3098 - ROC-AUC: 0.9935 - PR-AUC: 0.9937 - val_loss: 0.5903 - val_ROC-AUC: 0.7505 - val_PR-AUC: 0.7349\n",
      "Epoch 35/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2812 - ROC-AUC: 0.9984 - PR-AUC: 0.9984 - val_loss: 0.5877 - val_ROC-AUC: 0.7555 - val_PR-AUC: 0.7394\n",
      "Epoch 36/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2811 - ROC-AUC: 0.9958 - PR-AUC: 0.9958 - val_loss: 0.5871 - val_ROC-AUC: 0.7581 - val_PR-AUC: 0.7473\n",
      "Epoch 37/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2800 - ROC-AUC: 0.9965 - PR-AUC: 0.9966 - val_loss: 0.5878 - val_ROC-AUC: 0.7543 - val_PR-AUC: 0.7404\n",
      "Epoch 38/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2608 - ROC-AUC: 0.9964 - PR-AUC: 0.9962 - val_loss: 0.5891 - val_ROC-AUC: 0.7556 - val_PR-AUC: 0.7416\n",
      "Epoch 39/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2555 - ROC-AUC: 0.9983 - PR-AUC: 0.9983 - val_loss: 0.5875 - val_ROC-AUC: 0.7559 - val_PR-AUC: 0.7431\n",
      "Epoch 40/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2521 - ROC-AUC: 0.9966 - PR-AUC: 0.9962 - val_loss: 0.5892 - val_ROC-AUC: 0.7576 - val_PR-AUC: 0.7457\n",
      "Epoch 41/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2340 - ROC-AUC: 0.9996 - PR-AUC: 0.9996 - val_loss: 0.5860 - val_ROC-AUC: 0.7615 - val_PR-AUC: 0.7502\n",
      "Epoch 42/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2302 - ROC-AUC: 0.9979 - PR-AUC: 0.9979 - val_loss: 0.5808 - val_ROC-AUC: 0.7660 - val_PR-AUC: 0.7513\n",
      "Epoch 43/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2228 - ROC-AUC: 0.9992 - PR-AUC: 0.9993 - val_loss: 0.5809 - val_ROC-AUC: 0.7669 - val_PR-AUC: 0.7527\n",
      "Epoch 44/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2269 - ROC-AUC: 0.9982 - PR-AUC: 0.9982 - val_loss: 0.5763 - val_ROC-AUC: 0.7706 - val_PR-AUC: 0.7566\n",
      "Epoch 45/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2056 - ROC-AUC: 0.9988 - PR-AUC: 0.9988 - val_loss: 0.5723 - val_ROC-AUC: 0.7743 - val_PR-AUC: 0.7613\n",
      "Epoch 46/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.2119 - ROC-AUC: 0.9967 - PR-AUC: 0.9967 - val_loss: 0.5703 - val_ROC-AUC: 0.7775 - val_PR-AUC: 0.7645\n",
      "Epoch 47/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1863 - ROC-AUC: 0.9996 - PR-AUC: 0.9996 - val_loss: 0.5698 - val_ROC-AUC: 0.7783 - val_PR-AUC: 0.7638\n",
      "Epoch 48/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1925 - ROC-AUC: 0.9994 - PR-AUC: 0.9994 - val_loss: 0.5660 - val_ROC-AUC: 0.7863 - val_PR-AUC: 0.7730\n",
      "Epoch 49/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1862 - ROC-AUC: 0.9990 - PR-AUC: 0.9990 - val_loss: 0.5584 - val_ROC-AUC: 0.7923 - val_PR-AUC: 0.7780\n",
      "Epoch 50/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1806 - ROC-AUC: 0.9988 - PR-AUC: 0.9988 - val_loss: 0.5578 - val_ROC-AUC: 0.7927 - val_PR-AUC: 0.7763\n",
      "Epoch 51/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1671 - ROC-AUC: 0.9998 - PR-AUC: 0.9998 - val_loss: 0.5571 - val_ROC-AUC: 0.7912 - val_PR-AUC: 0.7748\n",
      "Epoch 52/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1731 - ROC-AUC: 0.9996 - PR-AUC: 0.9996 - val_loss: 0.5550 - val_ROC-AUC: 0.7942 - val_PR-AUC: 0.7805\n",
      "Epoch 53/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1584 - ROC-AUC: 0.9998 - PR-AUC: 0.9998 - val_loss: 0.5508 - val_ROC-AUC: 0.7972 - val_PR-AUC: 0.7850\n",
      "Epoch 54/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1558 - ROC-AUC: 0.9994 - PR-AUC: 0.9994 - val_loss: 0.5518 - val_ROC-AUC: 0.7963 - val_PR-AUC: 0.7815\n",
      "Epoch 55/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1524 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5538 - val_ROC-AUC: 0.7963 - val_PR-AUC: 0.7793\n",
      "Epoch 56/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1543 - ROC-AUC: 0.9997 - PR-AUC: 0.9997 - val_loss: 0.5566 - val_ROC-AUC: 0.7966 - val_PR-AUC: 0.7797\n",
      "Epoch 57/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1446 - ROC-AUC: 0.9999 - PR-AUC: 0.9999 - val_loss: 0.5546 - val_ROC-AUC: 0.7954 - val_PR-AUC: 0.7788\n",
      "Epoch 58/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1481 - ROC-AUC: 0.9997 - PR-AUC: 0.9997 - val_loss: 0.5590 - val_ROC-AUC: 0.7948 - val_PR-AUC: 0.7796\n",
      "Epoch 59/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1426 - ROC-AUC: 0.9980 - PR-AUC: 0.9980 - val_loss: 0.5604 - val_ROC-AUC: 0.7937 - val_PR-AUC: 0.7770\n",
      "Epoch 60/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1391 - ROC-AUC: 0.9993 - PR-AUC: 0.9993 - val_loss: 0.5616 - val_ROC-AUC: 0.7910 - val_PR-AUC: 0.7728\n",
      "Epoch 61/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1357 - ROC-AUC: 0.9996 - PR-AUC: 0.9996 - val_loss: 0.5544 - val_ROC-AUC: 0.7992 - val_PR-AUC: 0.7813\n",
      "Epoch 62/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1165 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5499 - val_ROC-AUC: 0.8051 - val_PR-AUC: 0.7893\n",
      "Epoch 63/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1190 - ROC-AUC: 0.9997 - PR-AUC: 0.9997 - val_loss: 0.5491 - val_ROC-AUC: 0.8026 - val_PR-AUC: 0.7856\n",
      "Epoch 64/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1111 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5542 - val_ROC-AUC: 0.7973 - val_PR-AUC: 0.7803\n",
      "Epoch 65/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1101 - ROC-AUC: 0.9999 - PR-AUC: 0.9999 - val_loss: 0.5555 - val_ROC-AUC: 0.7982 - val_PR-AUC: 0.7826\n",
      "Epoch 66/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1063 - ROC-AUC: 0.9999 - PR-AUC: 0.9999 - val_loss: 0.5483 - val_ROC-AUC: 0.8026 - val_PR-AUC: 0.7870\n",
      "Epoch 67/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1054 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5462 - val_ROC-AUC: 0.8057 - val_PR-AUC: 0.7901\n",
      "Epoch 68/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1012 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5489 - val_ROC-AUC: 0.8047 - val_PR-AUC: 0.7892\n",
      "Epoch 69/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1016 - ROC-AUC: 0.9998 - PR-AUC: 0.9998 - val_loss: 0.5487 - val_ROC-AUC: 0.8072 - val_PR-AUC: 0.7936\n",
      "Epoch 70/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.1041 - ROC-AUC: 0.9999 - PR-AUC: 0.9999 - val_loss: 0.5462 - val_ROC-AUC: 0.8097 - val_PR-AUC: 0.7971\n",
      "Epoch 71/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0970 - ROC-AUC: 0.9998 - PR-AUC: 0.9998 - val_loss: 0.5514 - val_ROC-AUC: 0.8082 - val_PR-AUC: 0.7939\n",
      "Epoch 72/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0821 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5477 - val_ROC-AUC: 0.8093 - val_PR-AUC: 0.7941\n",
      "Epoch 73/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0807 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5491 - val_ROC-AUC: 0.8091 - val_PR-AUC: 0.7969\n",
      "Epoch 74/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0935 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5440 - val_ROC-AUC: 0.8124 - val_PR-AUC: 0.8010\n",
      "Epoch 75/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0841 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5424 - val_ROC-AUC: 0.8141 - val_PR-AUC: 0.8023\n",
      "Epoch 76/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0834 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5389 - val_ROC-AUC: 0.8147 - val_PR-AUC: 0.8028\n",
      "Epoch 77/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0716 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5417 - val_ROC-AUC: 0.8150 - val_PR-AUC: 0.8019\n",
      "Epoch 78/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0654 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5441 - val_ROC-AUC: 0.8131 - val_PR-AUC: 0.7998\n",
      "Epoch 79/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0625 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5393 - val_ROC-AUC: 0.8188 - val_PR-AUC: 0.8080\n",
      "Epoch 80/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0682 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5413 - val_ROC-AUC: 0.8175 - val_PR-AUC: 0.8059\n",
      "Epoch 81/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0692 - ROC-AUC: 0.9999 - PR-AUC: 0.9999 - val_loss: 0.5407 - val_ROC-AUC: 0.8181 - val_PR-AUC: 0.8061\n",
      "Epoch 82/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0658 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5372 - val_ROC-AUC: 0.8220 - val_PR-AUC: 0.8109\n",
      "Epoch 83/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0663 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5370 - val_ROC-AUC: 0.8210 - val_PR-AUC: 0.8096\n",
      "Epoch 84/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0701 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5424 - val_ROC-AUC: 0.8183 - val_PR-AUC: 0.8071\n",
      "Epoch 85/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0523 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5436 - val_ROC-AUC: 0.8183 - val_PR-AUC: 0.8073\n",
      "Epoch 86/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0547 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5454 - val_ROC-AUC: 0.8176 - val_PR-AUC: 0.8054\n",
      "Epoch 87/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0589 - ROC-AUC: 0.9998 - PR-AUC: 0.9998 - val_loss: 0.5500 - val_ROC-AUC: 0.8164 - val_PR-AUC: 0.8035\n",
      "Epoch 88/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0686 - ROC-AUC: 0.9996 - PR-AUC: 0.9996 - val_loss: 0.5475 - val_ROC-AUC: 0.8192 - val_PR-AUC: 0.8079\n",
      "Epoch 89/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0457 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5473 - val_ROC-AUC: 0.8171 - val_PR-AUC: 0.8056\n",
      "Epoch 90/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0501 - ROC-AUC: 0.9999 - PR-AUC: 0.9999 - val_loss: 0.5539 - val_ROC-AUC: 0.8151 - val_PR-AUC: 0.8038\n",
      "Epoch 91/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0574 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5638 - val_ROC-AUC: 0.8139 - val_PR-AUC: 0.8021\n",
      "Epoch 92/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0586 - ROC-AUC: 0.9999 - PR-AUC: 0.9999 - val_loss: 0.5643 - val_ROC-AUC: 0.8141 - val_PR-AUC: 0.8013\n",
      "Epoch 93/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0496 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5552 - val_ROC-AUC: 0.8174 - val_PR-AUC: 0.8054\n",
      "Epoch 94/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0494 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5378 - val_ROC-AUC: 0.8229 - val_PR-AUC: 0.8120\n",
      "Epoch 95/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0458 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5392 - val_ROC-AUC: 0.8229 - val_PR-AUC: 0.8130\n",
      "Epoch 96/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0511 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5420 - val_ROC-AUC: 0.8227 - val_PR-AUC: 0.8131\n",
      "Epoch 97/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0473 - ROC-AUC: 0.9999 - PR-AUC: 0.9999 - val_loss: 0.5453 - val_ROC-AUC: 0.8225 - val_PR-AUC: 0.8122\n",
      "Epoch 98/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0528 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5456 - val_ROC-AUC: 0.8234 - val_PR-AUC: 0.8126\n",
      "Epoch 99/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0404 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5478 - val_ROC-AUC: 0.8215 - val_PR-AUC: 0.8081\n",
      "Epoch 100/100\n",
      "483/483 [==============================] - 6s 12ms/sample - loss: 0.0407 - ROC-AUC: 1.0000 - PR-AUC: 1.0000 - val_loss: 0.5488 - val_ROC-AUC: 0.8238 - val_PR-AUC: 0.8106\n",
      "WARNING:tensorflow:From /home/jupyter-anbhimi/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ../classification_model_2_classes/assets\n"
     ]
    }
   ],
   "source": [
    "model_path = '../classification_model_2_classes'\n",
    "history = model.fit(X_train,y_train_cat, validation_data=(X_val, y_val_cat), epochs=100, callbacks=[reduce_lr])\n",
    "tf.keras.models.save_model(model = model, filepath = model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4786cefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 320, 320, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a83e76b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "\n",
    "model = tf.keras.models.load_model(filepath = model_path)\n",
    "predictions = model.predict(X_test)\n",
    "predictions_rounded = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "779d9fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(predictions_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "018be441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 0.86\n",
      "1 - 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "for p in list(set(predictions_rounded)):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict(X_test)[:,p], pos_label = p)\n",
    "    auroc = round(auc(fpr, tpr), 2)\n",
    "    print ('{} - {}'.format(p, auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0016732e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74,  8],\n",
       "       [19, 38]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab0099f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85        82\n",
      "           1       0.83      0.67      0.74        57\n",
      "\n",
      "    accuracy                           0.81       139\n",
      "   macro avg       0.81      0.78      0.79       139\n",
      "weighted avg       0.81      0.81      0.80       139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, predictions_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4733ecb-ced6-499f-9800-9bd5f587a384",
   "metadata": {},
   "source": [
    "## LIME Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bdf4b2-c3ad-41d0-93d7-ee9b95c8642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d196c2c-c02b-4a0f-9ed1-e4fbb7007bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # please change the value with the index of image in the dataframe\n",
    "filepath = train_data_dir+metadata_df['filename'][i]\n",
    "image = tf.keras.preprocessing.image.load_img(filepath, color_mode='rgb', target_size=(img_height, img_width))\n",
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97146366-85b2-42c3-94c7-aeb27a287203",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(image, model.predict, top_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe6822-1755-45f4-a3d3-a5a6c1a7eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(image, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3eddb-0f45-4bae-8418-de74f659a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[1], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(image, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45adf91-f0b9-4ece-91ef-76a60cff2a0a",
   "metadata": {},
   "source": [
    "## Grad Cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a5898-50ac-4959-a085-5e9c0b7f1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/vision/grad_cam/\n",
    "def get_img_array(image_path, image_size):\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=image_size)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return (array)\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "        \n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    \n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return (heatmap.numpy())\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path='./cam.jpg', alpha=0.4):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    \n",
    "    heatmap = np.uint8(255*heatmap)\n",
    "    jet = cm.get_cmap('jet')\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "    \n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "    \n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "    superimposed_img.save(cam_path)\n",
    "    \n",
    "    display(Image(cam_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c742258-caa0-480d-9580-d82e818a8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100 # please change the value with the index of image in the dataframe\n",
    "image_path = train_data_dir+metadata_df[filename][i]\n",
    "img_array = get_img_array(image_path=image_path, image_size=(img_height, img_width))\n",
    "model = tf.keras.models.load_model(filepath = model_path)\n",
    "model.layers[-1] = None\n",
    "preds = model.predict(img_array)\n",
    "heatmap = make_gradcam_heatmap(img_array, model, \n",
    "                               last_conv_layer_name='stage4_unit3_conv3')\n",
    "\n",
    "save_and_display_gradcam(image_path, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007d919-bee2-4b59-bf35-094ae9f8e761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
