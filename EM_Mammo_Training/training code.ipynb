{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import efficientnet.tfkeras as efn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, matthews_corrcoef, auc, accuracy_score, classification_report, recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate, add, GlobalAveragePooling2D, BatchNormalization, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91820, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data[\"ETHNICITY_DESC\"] == \"African American  or Black\") | (data[\"ETHNICITY_DESC\"] == \"Caucasian or White\")]\n",
    "tissden_5 = data[data[\"tissden\"] == 5.0].index\n",
    "data = data.drop(tissden_5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86312, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = data.drop_duplicates(subset=\"empi_anon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African American  or Black    13848\n",
       "Caucasian or White            13183\n",
       "Name: ETHNICITY_DESC, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients[\"ETHNICITY_DESC\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African American  or Black    43507\n",
       "Caucasian or White            42805\n",
       "Name: ETHNICITY_DESC, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ETHNICITY_DESC\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    86084\n",
       "Male        228\n",
       "Name: GENDER_DESC, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"GENDER_DESC\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert path to data csv here where image path is under the column png_path and the race label is under the column ETHNICITY_DESC\n",
    "data_path = \"\"\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([43507.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0., 42805.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data[\"ETHNICITY_DESC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_anon</th>\n",
       "      <th>ETHNICITY_DESC</th>\n",
       "      <th>tissden</th>\n",
       "      <th>GENDER_DESC</th>\n",
       "      <th>age_at_study</th>\n",
       "      <th>png_path</th>\n",
       "      <th>empi_anon</th>\n",
       "      <th>StudyID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5398957042576578</td>\n",
       "      <td>African American  or Black</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>66.306632</td>\n",
       "      <td>/home/jupyter-zaiman/data/mammo/png_kheiron/co...</td>\n",
       "      <td>77670546</td>\n",
       "      <td>MG Screening Dig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2758514113950519</td>\n",
       "      <td>Caucasian or White</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.719638</td>\n",
       "      <td>/home/jupyter-zaiman/data/mammo/png_kheiron/co...</td>\n",
       "      <td>90697978</td>\n",
       "      <td>MG Screening Dig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6928226311930500</td>\n",
       "      <td>Caucasian or White</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>68.299828</td>\n",
       "      <td>/home/jupyter-zaiman/data/mammo/png_kheiron/co...</td>\n",
       "      <td>32811576</td>\n",
       "      <td>MG Screening Dig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1546724535446938</td>\n",
       "      <td>African American  or Black</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>69.301902</td>\n",
       "      <td>/home/jupyter-zaiman/data/mammo/png_kheiron/co...</td>\n",
       "      <td>74534019</td>\n",
       "      <td>MG Screening Dig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9192518631958436</td>\n",
       "      <td>Caucasian or White</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>76.393081</td>\n",
       "      <td>/home/jupyter-zaiman/data/mammo/png_kheiron/co...</td>\n",
       "      <td>49367954</td>\n",
       "      <td>MG Screening Dig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            acc_anon              ETHNICITY_DESC  tissden GENDER_DESC  \\\n",
       "0   5398957042576578  African American  or Black      1.0      Female   \n",
       "6   2758514113950519          Caucasian or White      2.0      Female   \n",
       "11  6928226311930500          Caucasian or White      2.0      Female   \n",
       "16  1546724535446938  African American  or Black      3.0      Female   \n",
       "24  9192518631958436          Caucasian or White      2.0      Female   \n",
       "\n",
       "    age_at_study                                           png_path  \\\n",
       "0      66.306632  /home/jupyter-zaiman/data/mammo/png_kheiron/co...   \n",
       "6      79.719638  /home/jupyter-zaiman/data/mammo/png_kheiron/co...   \n",
       "11     68.299828  /home/jupyter-zaiman/data/mammo/png_kheiron/co...   \n",
       "16     69.301902  /home/jupyter-zaiman/data/mammo/png_kheiron/co...   \n",
       "24     76.393081  /home/jupyter-zaiman/data/mammo/png_kheiron/co...   \n",
       "\n",
       "    empi_anon           StudyID  \n",
       "0    77670546  MG Screening Dig  \n",
       "6    90697978  MG Screening Dig  \n",
       "11   32811576  MG Screening Dig  \n",
       "16   74534019  MG Screening Dig  \n",
       "24   49367954  MG Screening Dig  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 256, 256\n",
    "lr = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "TEST_BATCH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "unique_empi = set()\n",
    "for empi in data[\"empi_anon\"]:\n",
    "    unique_empi.add(empi)\n",
    "train_empi = random.sample(list(unique_empi), int(len(unique_empi)*0.6))\n",
    "valid_empi = []\n",
    "for empi in unique_empi:\n",
    "    if empi not in set(train_empi):\n",
    "        valid_empi.append(empi)\n",
    "test_empi = random.sample(valid_empi, int(len(valid_empi)*0.5))\n",
    "valid_actual_empi = []\n",
    "for empi in valid_empi:\n",
    "    if empi not in set(test_empi):\n",
    "        valid_actual_empi.append(empi)\n",
    "train = data[data[\"empi_anon\"].isin(train_empi)]\n",
    "valid = data[data[\"empi_anon\"].isin(valid_actual_empi)]\n",
    "test = data[data[\"empi_anon\"].isin(test_empi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"mammo_train.csv\")\n",
    "valid.to_csv(\"mammo_valid.csv\")\n",
    "test.to_csv(\"mammo_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            fill_mode='constant',\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            rescale = 1./255\n",
    ")\n",
    "\n",
    "validate_gen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51749 validated image filenames belonging to 2 classes.\n",
      "Found 17362 validated image filenames belonging to 2 classes.\n",
      "Found 17201 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = train_gen.flow_from_dataframe(train, \n",
    "                                              directory=None, \n",
    "                                              x_col=\"png_path\", y_col=\"ETHNICITY_DESC\", \n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size=(HEIGHT, WIDTH),\n",
    "                                              shuffle=True,\n",
    "                                              seed=1,\n",
    "                                              batch_size=BATCH_SIZE, \n",
    "                                              dtype='float32')\n",
    "\n",
    "validate_batches = validate_gen.flow_from_dataframe(valid, \n",
    "                                                    directory=None, \n",
    "                                                    x_col=\"png_path\", \n",
    "                                                    y_col=\"ETHNICITY_DESC\", \n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    target_size=(HEIGHT, WIDTH),\n",
    "                                                    shuffle=False,\n",
    "                                                    batch_size=TEST_BATCH, \n",
    "                                                    dtype='float32')\n",
    "test_batches = validate_gen.flow_from_dataframe(test, \n",
    "                                                    directory=None, \n",
    "                                                    x_col=\"png_path\", \n",
    "                                                    y_col=\"ETHNICITY_DESC\", \n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    target_size=(HEIGHT, WIDTH),\n",
    "                                                    shuffle=False,\n",
    "                                                    batch_size=TEST_BATCH, \n",
    "                                                    dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = math.ceil(len(train) / BATCH_SIZE)\n",
    "val_epoch = math.ceil(len(valid) / TEST_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "base_model = efn.EfficientNetB2(input_tensor=input_a, include_top=False, input_shape=(HEIGHT,WIDTH,3), weights='noisy-student')\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dense(2, name='dense_logits')(x)\n",
    "output = layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "model = Model(inputs=input_a, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr),\n",
    "                    loss=tf.losses.CategoricalCrossentropy(),\n",
    "                    metrics=[\n",
    "                        tf.keras.metrics.AUC(curve='ROC', name='ROC-AUC'),\n",
    "                        tf.keras.metrics.AUC(curve='PR', name='PR-AUC')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_name = \"Emory_Mammo\" + str(HEIGHT) + \"x\" + str(WIDTH) + \"resnet50-race\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_date = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1,\n",
    "                              patience=2, min_lr=1e-6, verbose=1)\n",
    "ES = EarlyStopping(monitor='val_loss', mode='min', patience=4, restore_best_weights=True)\n",
    "checkloss = ModelCheckpoint(\"mammo_efficientnetB2_binary.hdf5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.device(\"/device:GPU:2\"):\n",
    "    history = model.fit(train_batches,\n",
    "              validation_data=validate_batches,\n",
    "              epochs=100,\n",
    "              steps_per_epoch=int(train_epoch),\n",
    "              validation_steps=int(val_epoch),\n",
    "              shuffle=True,\n",
    "              callbacks=[reduce_lr, checkloss, ES]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-cuda8",
   "language": "python",
   "name": "tf-gpu-cuda8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
